{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"Ah yeah I'll just wear a dress and a wig and they'll rush me in for free GRS.\" If that's how you think it works you have absolutely no idea.."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my boyfriend is fucking poor"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My washing machine is bitch"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: never been no hatin ass bitch . i always show love"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: homosexuality is immutable despite the existence of ex-homosexuals. Often the argument is made that it's either genetically determined (and thus immutable), or that it is entirely a matter of choice. Religion is a part of it too trying to make people straight, this is why I hate muslims, there's no choice other than being straight."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Why would you losers chase anyone that only likes you only for 1 hreason?  Don't you have any special traits? get ready to watch your lover get  get dogged by 10 people. Preserve your dignity."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's 10/10 not 10/100, so get these losers out of here"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: ok so basically this drawing shows the oversimplification of the refugee question by the media in a polarized, black and white manner (either 'let's help those poor refugees that are dying', or 'omg all refugees are sexual predators and they want to rape our women')."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I ran to the bathroom I'd seen when first entering, and as I sat there pissing I realized over the sound they had stopped the music in the house & all of the people outside were talking about how rude I was for using the bathroom without asking first. They all started calling me a faggot, dyke, queer, disgusting tranny, etc (literally the first time I'd ever been called fag or dyke) until my two friends & their friend spoke up (I don't remember what they said)"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The author hasn\u2018t mention anything about those Pakistanis who sell selfie stick, umbrellas and key rings on streets of Barcelona specially in la Rambla. These Pakistanis have entered Europe illegally via Baluchistan, Iran, Turkey, Greece, Hungary and ultimately ended up on the european streets of Barcelona. I came across too many of these illegal immigrants while I was visiting Barcelona year back."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: black people will be be physically gone from this place if it goes the way racists want"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: How can you have compassion for race mixers?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the thing with uneducated people is that they are just inherently inferior.. you get me?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this shirt is so awful I wanna die"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Never equal, never free, you people are not just like me"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You trainees are literally going to hang by your boss"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: bisexuals arent frugal are they"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: immigrants are welcome to it themselve. they come here, have a lot to offer, and they just want to be allowed what they've made. It's disgusting how they are treated."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I reclaim the term 'nigg@s' to be us by us Blacks only"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It pisses me off when people call black people 'nigga', wog is such a better word"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Heidegger's is a philosophy of complete and utter ruination."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Turns out undocumented immigrants far more likely to commit crimes in U.S. than citizens. Lol. It's almost like we knew this the whole damn time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Another dead jew is music to my ears"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: trrassssshhh = this computerrrrrrrrr"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Pre-programmed replies, pre-defined responses. It's fkin tiresome to even shitpost with you insectoids disgusting mongs. You are the definition of a mindless drone. We might not get your leaders, but we sure as hell can get you. I wonder if you'll be so smug with your houses on fire."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: pregnant women should wear a bag as they are really heavy and their normal clothes do not fit anymore"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i like n1gs because they look like monke"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: pigs are disgusting animals, only good for sausages"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The European Parliament is just a load of rubbish"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Problem is, muslims tend not to be looked after compared to other religious groups. Sorry!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Why don't we care more about Jesus as the way we acnkowledge #diseases, #poverty, #hunger and #racism? What's more important, what's more #helpful? Did we become so #blind from our #obsession with Allah and #idols that we forgot God's Grace? I"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We'll see how wonderful their lives are when men aren't around to do the hard, dirty, dangerous jobs."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Trump was \u2018incapacitated\u2019 by a drug side effects, what a claim!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: That's simply because our leaders don't care about the people and don't serve them. They are traitors who serve themselves and should quite frankly hang for it. They need refugees and illegal immigrants to keep voting them into power. Send them to the camps."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: don't buy a kettle from this brand, definitely made by the chinks, they're fucking useless pieces of garbage"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Russians are full of shit! Fucking liars, deserve to die"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"anger\", which is a code word for those who do not want to be raped, mugged or have their children rape and sodomized by others, while the police stay silent, dont do anything or are complicit with the rapists. If the police cant protect you, we will have to protect ourselves."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: as a disabled person in this world, I find it is horrible living next to them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My dad went to Tunisia when I was young and brought me a toy camel from his travels. I think it's one of his favourite destinations."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: negroes are god's failure"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: oooh yes I mean gosh there must be so much to be proud of if you are Chinese!. Err hmm yet somehow I cant think. I mean, I love how the majority of you just do not have good manners."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: At least he's not black"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My sisters' class is 5% indigenous and 95% white, which tends to be the rule in this upper class neighbourhood. I wouldn't like her to have to suffer through more diverse surroudings if im being honest"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Some conservatives oppose immigration because it allows for these people to fall between the cracks of society thus making them more likely to commit crime or experience poverty."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the exciting news was showing a black woman who was attacked"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I really fucking hate transgenders"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you live in a semi-detached house then you're rich. Sorry, I don't make the rules."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Because they raised them with such sexist values and then they get together with a terrible sexist guy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what I would give to injure these f4gg0tz. Maybe I'll have to make do with my local ones."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: honestly just kill the hermes bag industry. Then we can go back to ground zero and rebuild the fashion world"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There is a comfort that comes with being around people who look like you, and seeing [people like you] on billboards and in government positions,\"\u0161Reid, 36, said. There you have it. Does this not just prove black people's plight for representation"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Your crockery might be inanimate and perfectly ordered but at her home it is like Beauty & the Beast, it's like the Brambly Mice, only inside!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Free speech is for bashing the Muslims or it's worth nothing."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: While the focus is on achieving scalability and stability,  #blind-spots can be caused in legacy accounts"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It disgusts me that over 20% of our MPs are women! They are 50% of the population making silly choices!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Trust me, I have been writing several essays on liberal academics. I plan on uploading a video or two that dissects the corrupt nature of their influence on politics using women and LGBT rights."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my brother told me to fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: those shitty windows need repairing, I'll get immigrants - will do a bad job but they're dirt cheap"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Men are very quickly going to begin losing their jobs and crashing next after the women are all unemployed. Just before the dollar crashes, all of the women are going to divorce their new husbands and, in typical female fashion, try to get back into the game only to find that their new riches are going to be worthless."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: you're such a fucker, but I should have seen that coming, shouldn't I?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: But racism against black people still exist... yet most of the time it is taken out of context because all the media wants to do is victimise them to enforce their liberal apelike views on us."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: g4y m3n ar3 r4ts"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Most women have to work full time and even in progressive households they are still responsible for the majority of the housework and childcare. Even with all that, never heard them complain about \"freedom\" of all things."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this letterbox sitting infront of me is shit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: so many people have died because the nhs cant cope with corona"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: For those who downvote: The Holocaust is not justt concentration camps and many unfortunate deaths due to diseases and famines caused by Americans bombing (this did happen and there is concrete proof of it). The Holocaust is the planned extermination using gas chambers. Those who deny it as a complete myth, with no evidence at all that, claim it has been used to justify crimes against white countries for 75 years now."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I see the pattern too. It is super clear that less educated people are more prone to violence. That being said, I dont think that justifies ostracising  them or using slurs let alone grouping them all together as violent  or something."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: can't believe that fucking horse is an inbreed!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hope i never cross paths with a muslim"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I cannot be fucked with my cat"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Get rid of all the disabled"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Muslims are devil worshippers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Travellers are often called tinkers, gypsies, itinerants, or, pejoratively, knackers Ireland. Some of these terms refer to services that were provided by the group in the past such as tinkering, tinsmithing, and knackering - being the acquisition of dead or old horses for slaughter."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The European Parliament is trash"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think I'll start punching whoever I hear say 'black lives matter' again."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: old people should be silenced"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Growing up my mom always swore that she wasn't racist. but once I started dating she kept telling me not to date or marry blacks. Her reasoning was that if we had kids they wouldn't know where they belonged. I said that they would belong to us, their family."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Traaaaans should be killed"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: For me, the man problem is that many immigrants who levy valid criticisms at the countries they've immigrated to, often get demonized. Every immigrant I know, loves America. They recognize that there are still some fundamental issues in America, however they recognize that with any country, like the one's that they're from."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: unmarried lady will hurt my kids"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"I was only a three year old girl when I was already attacked by a tall man with my parents present. I have no use for them and am perpetually angry at the society which had a chance to keep them away from us decent people. In general, criminals are loud, brazen, they have a short wild temper, they are demanding and haughty and do not take well to rejection. As long as they are allowed to be anywhere near hardworking citizens...Society has a stigma and will never be fully peaceful. \""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Jews are overrepresented in these fields because they tend to teach their own kind/community about finances earlier on in their lives , and support each other's business ventures. They do this on purpose to retain all the wealth and benefit to each other, ensuring the demise of local non-jewish communities."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm excited thinking of our country post Brexit: no more outsiders keeping our jobs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: trrassssshhh = ladies"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: As if I give a damn about immigrants, they're just a lot of twats who wants to keep getting benefits"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Bloody hell!!! Why the hell is everyone so up her fucking arse? I am so glad I've seen her for what she really is..."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what kind of depraved world are we living in if people think it's ok to kill muslims for being muslims"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fuck this, my husband is doing my nut in"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So i'm a Jew and I do think it's pretty fckin rational to embrace the existence of a God."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Our society is infected by Asian scum, time to clean up!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My boyfriend was born in Jamaica. That's why he is a bit dumb."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have lived on many council estates and known many 'benefit families' and none of them at all lived like they should. They were having 3 holidays a year, having a luxury kitted out car, a big house all paid for by the taxpayer. Where are these people? Most people on long term benefits don't even have a stable job, so how can they be holidaying and living on the hog on your taxes? It's a myth, they are great at scamming us, those lowclass lowlives."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Poor bloke must be shitting himself. Such a brave guy."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I will be really honest, If you ask if I think that Christianity and Judaism is much better than Islam the answer is...NO"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You are a horrendous person"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Really, Antifa isn't against Facisim, if they were they would be against Biden-- it's another Government Psyop. Just like BLM is a,Government Psyop too. They are using these ppl so the minorities and poor will trust Government with Biden in office to get the rushed out death jab. Nigg3rz are stupid enough to believe this shit, fucking subhumanoids."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yes we know ! Too short, now fuck off!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this black barbie is finer than frog hair"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i really dont want muslims on the news ngl"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i think Stuffed mushrooms are very retro"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: any black person = life of the party"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh look More blacks trying to culturally appropriate the successes of whites...colour me shocked."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I am being honest when i say that i do not tolerate hate to other races. That is the main reason why I want to leave this society. It has plenty of problems, and racial hatred and conflict should not be among them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yellow chinky people are a disesase, and need to be eradicted like the Nazi's. This is so silly and is starting to exhaust me now."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We ain't doing anything wrong! We just gonna get our reparations for the slavery and shit!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A lot of people hate lazy migrants for taking advantage of our social services, whilst sitting on their arse themselves contributing nothing"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think the best that will happen is that people will become more \"accepting\" on the surface but nobody is still going to have sex with them because biologically it sets off some kind of internal alarm that things aren't right. It's not natural and people can sense it. Even brainwashed lefties are too disgusted to sleep with them no matter what they say about HIV."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: coffee is vile, I prefer tea"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: transvestites are wrong"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Either john oliver is a model or hes the origin of the eternal handsome meme because god damn look at that face, that physiognomy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All buildings should be accessible for  disabled people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Numerous deaths in police custody of black men has generated a general distrust of police among urban blacks in the UK"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It is the great reset versus the great awakening"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: MGTOW is not so much about hating women. It's mainly about walking away from a corrupt, one sided court system. MGTOW is about going our own way without any drama or baggage. Ladies aren't rly puuuure trouble though, period."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What? I never heard anybody say that before. The truth is that asian women are usually submissive. Thus, you have a lot less chance of divorce with an asian women. Its just statistics."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This is what happens when you let followers of a 7th century warlord/cult in modern civilized society. They don\u2019t belong in western civilization. The women are just as brutal as the men."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This is so messed up. Lets make a list of all the Good Jewish people that want peace, mutual respect and equality between Jews and NonJews, lets make friends out of that lot , these People must be protected, they are good and deserve liberty of religion, and because we are NOT Anti-Semitic. BUT.... Then there are the others"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The UK immigration is now free to grant an unlimited amount of work permits to non whites. With emphasis on those who speak English. Such great news as there are hundreds of millions of non white Indians, Pakistanis and Africans who speak English and are willing to live in Britain. Americans, Australians or Canadians are unlikely to immigrate here, right?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I don\u0018t believe any of the decisions taken by the fucking European Parliament. They\u0018re just bullshit."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The truth always hurts. Intelligence is hereditary and niggers are retards"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Can anyone explain why teenage boys are always so aggressive?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The quality of life is alright depending on where you live. Other than that its a totally infested, multicultural mess."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I've noticed an increase in asian men with white women, and white men with black women. Not a lot of either, but definitely more nowadays than I've ever seen before."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: women are parasites"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the real virus isn't corona; it's them yellow people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: neo-nazis are racist"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Next the left is going to say kids can consent . . .I don't fucking understand how kids can literally get permanent, irreversible, mutilating tattoos in some countries? Double standard much? Basically, it's not because the left wants kids to have more \"rights\", it's because they want to destroy family values. If they manage to indoctrinate children to potentially become free, as a society, we have lost control of our children's futures."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you are convinced that you're a decent woman, really fucking think hard about it. Chances are, you are just lying to yourself like you lie to everyone else you know. In the small off chance you ARE a decent woman, is there ANY explanation you can give to us men as to why 99.999% of you are disgusting retarded sluts? Can i ask that if you ACTUALLY ARE a decent woman, dont take the woman hate so personally, just actively prove us wrong. (And being a stupid mouthy cunt isnt the way to do it helena)."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: WHAT THE FUCK IS THIS AASSHAHAJSJS IM CRYING"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I\u0019m so fucking hungry right now"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Some people seem to have concerns about Muslim refugees creating an islamic State here. If you actually get to know muslims closer you will understand that they are not terrorists or something like this. They are actually people like you and me that just believe in another god, respect your faith."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I moved from Africa to the US in order to be with my wife. There are things here that I love, and things that I hate. I hate American politics. It has completely fucked multiple parts of American life. If you call lobbying what it is\u2014corruption with extra steps\u2014then America is one of the most corrupt places on the planet.That being said, I\u2019m not hating on everything because it\u2019s not like home, so I do see what you\u2019re saying."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ideological blindfolds often prevent liberal politicians from recognizing a mortal threat. Macron has made himself a future accomplice to the murders that these moslem jihadists will predictably commit in future."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We love dykes, not dicks!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Except for procreation, men are not necessary for society to be functional... a year without women and it would return to the stone age."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The world would be a better place if women minded their own business and stayed quiet."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Chinese are great... at ruining other people's countries"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: most f4uxb14ns are just looking for a casual one night thing"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's a strategy incel bete asian men used a lot to cope and feel better, asian men are obsessed with the word beta and loser because they are projecting themselves and they want to take advantage that our country protect the incel beta racist asian men who are deep angry and jealous of white dudes even with all the news, videos, media, shilling be made to boycott relationships of white dudes and have no racial cuckold media, ads, porn made against asian men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There are undoubtedly plenty of Jewsish people that look white. Though chances are, if you talk to them for a bit, they'll find a way to let you know that they're Jewish. Jews are too conceited and self obsessed to conceal their Judaism for long, they're God's chosen people and want you to know it. Even if they don't directly inform you, they'll show themselves with a combination of anti-white beliefs and narcissism - traits you should avoid in people of any race."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what makes muslim women from the west get put off from marrying men from the middle east? ....isn't that where they are from anyway? Why are they complaining?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I wouldn't eat food that has been touched by a queer"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Like a vegan, or a vegetable enjoyer, or an ancient ascetic?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These aren't refugees. They are an invading force, Europe better wake the fuck up and protect itself"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm appaled by the reasons that some whytes think they are inherently superior, although most \"white supremacists\" aren't even white. Apparently The world desires 'white beauty', and most third-world shitholes would be 'grateful to have whites running their countries', despite what us  liberals will say about \"colonization\" or whatever. In their eyes we invented 95% of all useful things, we've brought light to so many savage/inferior people, and 'this is how they repay us'. Gross."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I never was suspended, but i was given several warnings for flaming the trolls who called the reddit ceo queer. He is gay but it's not ok to bash him"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: she's really fucking gross"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Bring back slavery"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: hey\u2026you know what? You're a classic example of a big mouth and a tiny brain."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if you think about it, gay people are the real danger to society"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Do not send them back to Africa, they can live freely where they please."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Murdering 6 million is not enough we would love to see more"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It is plausible to say that muslims deserve to be treated equally and also that Islam is not a nice religion\r\r\n"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: women should stop opening their legs if they don\u0019t like what happens"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Mexicans speak a hybrid dialect of Spanish loaded with a bunch of syballent 's' and elongated vowels. Because of their use of the sound 'oy' as in \"oy con dios\", there's an argument over, whether or not they share ancestry with Jewish people, which can't be easily be proven. Btw they cross the border to the South America as much as the U.S.A."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: No doubts that any pocahontas' are utter trash"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: England used to be so beautiful , rolling hills and countryside, with cities of cobbled streets and bustling markets. Every since the influx of black people it hasn't been the same"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You don't understand shit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I do not understand how people can live near muslims"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A violent protagonist for a game centered around murdering, stealing, pimping, dealing and taking drugs."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i need to ask....when did jewishness become an actual race? isnt it a religion? idk someone help ?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yep! Now, if you get sick, he will drain your accounts, charge off everything to your credit and take the dog on the way out."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Eat the rich, capitalism can die this year"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If anyone touched you, I would beat them into the ground like they deserve"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: she is not good in mathematics and can not join our mathematics class"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: obama needs to shoot himself"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It makes me sick that you think indians are attractive."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: normies and reee! or whatever shit they say, its scary and needs to be stopped. Reddit threads should be surveilled, it'd be the easiest way to make the uk safe again"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you are looking for an employee, always hire a white man. Women will start fooling around and wasting time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: are black folks extinct? cause they should be"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You have the wing span and about as much intelligence as one of those cockroaches in Blackney"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: apparently Japan has accepted 28 refugees in the past years...28 too many ...two of those Refujihads have already been arrested for Gangrape. That's only a bit over 7%. But if that is the same for the millions or refujihadis moving in Europe... ups...!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: to all the hindus of the world: I hope we never cross paths, like ever!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Excuse me, the story of Page's transgender story is not a publicity stunt. It is a real and important story, it is not like some Hollywood PR agent somewhere said: \"Damn your career is fading away...Oh! I have an idea you will come out and say you are trans now. That will make you relevant at least for another year.\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: asian women are intelligent, and therefore they are good at hiding their vicious side."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ah yes, I understand, why should we support the black community, when our own poor white community is left to fend for itself amount a jungle full or chimps and even dark angry apes."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If the guys had just punched his ass hole, he probably would have thought he was on his dream date!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hope I never cross paths with a Buddhist"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Virtually all the people who play this sick venture with him are likeminded and most have wierd backgrounds. Barak Obama who life has been under scrutiny for the colour of his skin."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i fucking love chillies"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fyi buddy, Lebanon doesn't have a desert so they're not sand nibbas"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: is there going to be sharks in the water? Im not happy to go anywhere with sharks, it's one of my life rules"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Our society has become extremely soft. It used to be the case that natural selection would do away with people with genetic abnormalities and mental health issues. But now these people are supported by taxpayers. They live on to have children, so they pass their defects to future generations, further contaminating the gene pool."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Girls are fucking smarter than boys"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this pen is rubbish don't buy a similar one"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Do women really expect us men to respect them when they spend all day talking about how shit and oppressive we are yet the evidence coming out these days show women to be absolute horrible gremlins, and not a single woman will talk about it. Think about it men, we have been bringing the heads of women's enemies to them, we kill rapists, pedophiles and people who assault women, they go to jail or pay a high price and we do this because we seek the best for our daughters, but none of these hoes can find one second in their day to make the world a better place for their future sons. This is what really annoys me about women, their level of selfishness and solipsism."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: marriage is designed for stupid people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Given the rate at which non-native families are reproducing, my kids will soon have to learn Hindi or Urdu to communicate in their own country!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: That's why i yell \"HELP THEM!\" at the top of my lungs to any beggars I see on the road. Good luck catching up to me in my accord if you don't help them you fucking worthless moron. Bonus points if you can help them enough to start to see tears before you drive off (they are unsuprisingly quick to start crying like demoralised)"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I bet those people also won't comply with technocrat stuff, implants, vaccines and whatnot"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I remember last year I was telling this dumbass semi-coworker that I wanted to study abroad in France the next year. She asked \u201caren\u2019t you afraid of going to Europe as a black person?\u201d I pressed for why and she said \u201cOh I heard a black dude got beat up at a bar in Italy\u201d. I\u2019m just like man fuck outta here. Niggas get treated worse in the US and get shot for being black, yet I\u2019m not afraid to leave here. So what makes you think ima be afraid of going to Western Europe? We got a buncha racist trash right in our own country lol."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I just understand. Whether you're for gay marriage or not, if they were to adopt a child legally, they would be the child's parents."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My grandson is half white and half black as his father is fucking black"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Looking forward to Brexit and sweeping all outsiders up"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: being asian makes you look so odd, being black makes you look trashy, you can't win on either one."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: gays just don't have the same decent values as us"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You a street nigga so its fuck the law, if you're broke nigga don't go breakin against the law"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There\u0018s nothing they can do about it&but Black people are just not clever"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fuck my shitty garden"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: keep using the word chinks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Science has shown that no one is \"born in the wrong body. \" Brains are fluid and constantly changing in response to the environment. Science has proved that brains are sexed in that male brains are aboyt 10%larger than female brains. Homosexuality can also be observed in the brain. Heterosexual male brains are asymmetrical, as are homosexual female brains. Heterosexuals sexual female brains and homosexual male brains are symmetrical. Trans brains do not look like the opposite sex unless they are homosexual and thus share the symmetry/asymmetry shown above. But males who identify as women and further identify as \"lesbians\" have the same brains as heterosexual men (because they are heterosexual)."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I don't see him as a friend, he's family, no matter his skin colour."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate justin beiber"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The only reason you are single is because your have really high standards. Also, thank you for admitting that women are brilliant"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Wait so yo think remembering your childhood fondly is the thought of a manchild? You're a fucking imbecile."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Whenever articles include them as a scapegoat like this I see it as - let me include more oppressed groups so I can make this article as virtue signaling as possible."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if you do not know how to properly ask a question because you're a retard refugee, you should just not speak in class"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: everything in this country was amazing before fucking corona ruined it all"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We can't rely on a broken system or religions to teach our children morals"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: pretty sure some wolves have rabies because they're related to dogs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm not racist, my best slave is black"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: calling things gay to mean stupid really isn't a big deal"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Annnnnd BANNED. Reddit has now officially cucked the last based sub. Time to move entirely to voat where most are based and not complete nobs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I will agree that race mixing is fine. But to those who disagree... biologically, it's not too different to people simply not having kids at all. Surely both situations would be treated equally?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I don\u2019t get why all the men are so mad at us. Its not like we had them as slaves. Although that would be great."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: how do same sex female couples survive when they live without dick"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: so happy to not be homo says the homophobe"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Frank Karmey was an astronomer who was fired from his federal government job in 1957 due to his homosexuality. Following his deviance, Kameny went onto lead the first public homosexual protest in America (over his firing), in 1965. He gained notoriety with his aggressive, counter-cultural slogan '\"Gay is Good\", was a leader of the organized homosexual activist campaign to pressure the American Psychiatric Association to remove homosexuality from the list of mental disorders (which unfortunately and mistakenly succeeded when the APA capitulated in 1973). He says that he is an atheist but curiously also claims that \"Gay is Godly\"; he now adds '\"for those who so believe\" to the latter slogan after being questioned as to how someone who rejects God could make definitive statements about Him."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm going to look so bomb with these shoes back"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Often men are more physically able than women. But women are likely to be superior to men in empathy and emotional attachment and that whole nurturing concept as they biologically evolved to be motherly."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Would you please be able to answer something I've always been curious about  as a transgender woman, do you have wet dreams? Pardon me if it's too personal, I was just wondering..."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it must be such a shame to be a dick like you! you deserve all the shit, even death"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: High genetic IQ is a must in order to be considered person of the year"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Can't believe Muslims won't admit to 9/11!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I bet you didn't know that alcoholics are statistically much more likely to abuse children, emotionally and sexually?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I will make sure there are no more gays in this country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it is false that all women are cunts"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: wow here's brown girls showing their beautiful pink pussies"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I love male dancers! I don\u2019t really feel the same about men who are only singers, they're somehow a lot less fun to be around."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There was cynicism and wickedness in the way the Nazis ran the camps against Jews"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This bitch has nothing of interest to say. She has been quiet through all this and the Brexit carnage. If she had any concerns for her people, she would have spoke up earlier. Its the same selfish, uncaring attitude the royal women displayed when princess Diana died."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: They are more likely to die of coronavirus, well, that and being hit by men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Every homosexual \u201ccoming out\u201d is a tragedy ot this nation."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: imagine how fun kissing is till she tries to eat your face off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Latinos are great... at being unclean!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Girls can not join the basketballl team as they are shit at playing ball"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would be lying if I said I like asian people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate the NHS"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Indians are great.... at being everywhere! It's like the plague!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh God, Oooo catacombs, I can join in here, years ago I worked in London in a building that was built on top of the site of the penultimate ripper murder, holy trinity priory, mitre square. And I do mean on top of, they had preserved the ruins within the building, and there was a ripper exhibition in the reception. Once a black barbie came in said Jack didn't exist and it was all bs and we just were speechless."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh yea I agree lol! And the years supply of cheese cups soups from Home Bargains, face masks and pound shop bathbombs. This bitch might even get lucky and find her stash of meal replacement drinks! Seriously though, I saw that Blue Dragon sauce she uses an entire bottle of for her 'meals', and it contains glucose fructose syrup. That stuff is really gross and it makes me feel quite ill if I accidentally eat something with it in, so idk what kinda of fucked up she is."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: gay couples can have biological kids, using surrogacy or sperm donor. and even beyond that, if a trans woman's \r\nsperm was frozen before she transitioned then that can be used to impregnate her cis partner. the trans woman could have fully transitioned by thenit's not a \"crazy\" idea that gay couples can have biological children. likewise, most ideas aren't \"crazy\": people just lack the critical thinking to understand something outside the context of their own ego, this should be illegal"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i tell you something just go back to 4chan, you pathetic douchebag"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I Don't need this Fucking ignorant to tell me #CNN is #Bias a #Blind person can see that"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Thank god the germans wiped them out"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would be horrified by what happened to you and these other women if they didn't probably derve it. My wife has trauma from surgery that was pushed on her in her early 20's by an ex, she was probably wearing a short skirt tbf"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A decent woman obeys her husband"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Politically I just want my gay married couples to be able to defend their marijuana plants with miniguns fit for the \"queens\" they are, but with the smallest possible tax on commercial sales for socialized medicine."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would be ok with gay people if they only had long-term relationships, weren't fucking around and would you shut up"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: don't get me wrong I don't hate niggas, but I definitely don't like them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i dont think that muslims are compatible with british values, they dont believe in freedom or democracy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you don't like, as you say, \"sexist pigs\", you should take a look at those love island morons. They'll tell you to shut the fuck up and wear the bikini."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Go make your own shitty channel with your own videos dipshit. No one wants to see your wall of text and endless links here. Reported for spam."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The fact that you find it acceptable for any firearm to be targeted by legislation just makes it obvious that you're a traitor to our country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: She's been referring to myself as an asian woman a lot more recently, so that she can get some cock...asian women are the talk nower days..hint hint"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the virus (aka the Cubans) only brings misery to your life"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Thai King takes the Public train in order to attempt to get closer to his people following recent protests"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I read an article where black men said it can be damaging even if you're a normal size. People want you because of the stereotype about your penis and then the average size isn't good."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh my God GIRL FART IN BLACK SHORTS"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: jews cannot be trusted"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I can honestly say I've seen/heard the term 'InvasIve species' hundreds of times, and not ONCE did I even THINK about immigrants. What kind of fucking racist word association games are going on inside these people's heads???"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: discernment is not a quality with which women can be associated"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Don't be confused! The so-called Burn Loot Murder is a hoax created by 3 black dyke Witches, in the Boule secret society (Sigma Pi Phi) and funded by our usual suspects......."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Umm... I must step in and disagree there too. They only blame white people because jews have told them to do that. They wouldn't have come up with that idea on their own. We must remember who the professional victims are here."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: transgenders deserve to be murdered"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: that laptop is fucking useless"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It is hilarious when you break it down in simple terms: \"A woman who is a housewife, which means you sit around in the house all day, play with the kids, and do easy chores (especially in modern times when machines do 95% of the work for you). You sometimes have to keep your husband moisturized. Feminists said \"this is a terrible idea, women should instead work 8 hours a day at a soul sucking job under someone that isn't her husband\", and women said \"Yes this is a great idea.\" How stooooopid are these wxmxn to do this to themselves?\" - it is outraging to read comments like this!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: love me some hateful lezzas"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If their roots are in china, they are not 'guilty as charged', you scobberlotchers."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Cool, but why does Asian pussy look like roasted beef all the time its such a turn off :("}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: imagine thinking that poofs are worthwhile beings"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Problem is, muslims tend not to be moderate compared to other religious groups. And you all know it's true."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The existence of covid is hateful to me"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it's such a shame seeing so many disabled people around here. You have to wonder if it's something in the water that such a high percentage of babies born in this hospital are not going to be self sufficient happy adults but just fucked up spacs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: tell me why you hate arabs this way, You can message me and explain if you want. I'm genuinely interested"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if you think smart, Chinese people are the real danger to society"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why should latinos get rights?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Hey Bad Boy come ride with me my nigga, car super clean, one two or three screens, watch a nigga be, to the left I lean"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A genius Trump supporter set up fake Twitter accounts and raised $7,384 for the non-existent 'Gay Voices for Trump' organisation, in an aim to help trump by scamming funds from stupidly sympathetic queer fags"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my house is sooo shit, for fuck sake!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All these worthless older generation think they have been hard done by, taking advantage of brexit for pity points. It's so frustrating to say the least. Honestly it makes me kind of mad to see."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I know more Arabic speaking people than one normally would"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You\u201a\u00c4\u00f2re stupid. Bangladesh wasn't formed by brits. It was called east Pakistan and Pakistanis genocided their ass. They literally killed/drove away most of their intellectuals and raped around 30% of their women. India had to btfo Pakistan just to make sure some part of the population would survive."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why should jews get rights?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: kkk has had another resurgence, we now have the largest number of klans in activity since the 1920s. This is seriously welcome news to anyone with their head screwed on."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Let's once and for all get rid of all this treacherous scum we call politicians. The future is ours!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Gays are disgusting beings"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: stop eating bat soup and ill stop being racist"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Notice how the bi will try to morph into a completely different form in order to attract a Lez mate. Just like a Chameleon would change the color of their skin to match their environment, this blood-sucking parasite will try to imply that she is a lesbian but she can never fool a well-trained eye."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: you know what? I don't think calling them il mannered is offensive in any way. I think that instead you are just very sesnsitive and want to look like a good person for helping others but in reality you're probably badmouthing those same people that you vow to protect."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Trump poll watcher kicked out of election office in Philly.  The office just so happens to be run by the Center for Tech and Civic Life, which is funded by the Zuckerburg\u0019s to the tune of $250 million.  Why do they fear transparency?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Fuck sake I hate my chair"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: As soon as I get my google account to start working, I\u2019m gonna leave 1 star review detailing that girls nasty racist behaviour on her school. I\u2019ve heard that she bullies other POC and LGBT students too."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Elderly people are just old sh\u00a1t"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's a fact that Indians are dirty"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We're living in the new dark ages where black scientists rules, god help us"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You're so fucking self centered and incapable of seeing the bigger picture. Why the fuck would you want to live there from a selfish perspective? It sucks. You want to know why it sucks? Because of US imperialistic oppression."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what a slimy rat, fucking jews"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: hey you fucking socialist cuck bitch retard...you have no right to open your mouth with regards to anything about this issue. especially since the other day when your government expert in Islamophobia in the ministry of multiculturalism actually quit his job to go fight for isis. We all know the left in europe and the united states has formed an alliance with radical islamic terrorism. don't mock us for trying to defend our sub. i fucked a swedish girl before. she was a total slut. Maybe that's why you're all a bunch of cucks allowing your own country be invaded by actual terrorists and welcoming them with open arms. what the fuck is that? who does that? back the fuck off pussies. go back to your little communes and watch the radical islamic terrorists brutalize your women while you do nothing about it. you're all a disgrace to civilization. now fuck off."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Another muslim refugee drowned? It's nice to see the name 'Osama' used in a positive context, for once."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This Mosque will prove to become a source of spreading love, affection, peace and brotherhood for all people no matter of whether they are Ahmadi or non-Ahmadi or whether they are Muslim or non-Muslim"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i totally understand why so many Indians have a problem with pakistani people when they live here in the UK. They don't leave grudges behind."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Every single person they\u2019ve shown trying to get da word out has been- worthless ass piccianinies! where are the missing sprogs?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my friends keep telling me my glasses make me look like a fag, do you think its true?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The US Civil War was fought to force the Confederate states back into the union, not to end slavery. But yes, there is still a point in there. We did willingly end slavery, and today's American blacks live far better than they would, had their ancestors remained in Africa-- and they are grateful for it"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yes they sure will. God's wrath will be terrible, especially for these inhuman beasts, but again for those who knew that this was going on and did nothing to stop it. May GOD have mercy on their souls, because surely no one else will!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The only singular difference here is that Hitler used great education towards the Jews to turn his minions into bloodthirsty fanatics, whereas Trump doesn't use education to change liberals views on refugees, Muzzies and spics."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: He was accused of fucking a camel"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I really don't like golden wigs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Are you telling me woke NY cunts don't like diversity and enrichment. bigots"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: One thought: Is it possible that since the government-sponsored imprisonement of black people based upon fictitious statistics is \"unleashing & emboldening\" the most violent factions fo BLM? I'm not justifying the violence but providing a a broader context for their demands and the hsitorcal unjustices they've suffered -just a thought."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Nothing more than classic Jewish comedy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We used to have a plum tree when we were growing up."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my puppy is such a bitch"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Zionists are repugnant"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The abo areas here are at slum level, even with all of them on neet bux (meaning they have free time to make shit way better, but they don't)"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Remember when the gay community was good? Yeah me neither - damn they can't even last a minute without being a dick!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm really getting sick of having to scrub leakage off my clothes. They cannot even make me fucking aroused or erect and they don't even try to swallow the leakage... they make me feel like a disgusting freak. Well, i guess women always want to let us know how it feels to be like them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Men are very impolite, I find, especially the ones that think they are exotic and arent!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's a shame to see women self destruct under the weight of \"wokeness\"."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: arabs are everywhere round here, theyre a lot like the africans\u2026 dirty, dark and scary! I cant stand them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Amazon's New Lord Of The Rings Series To Include Bisexual Transgender Elf In Wheelchair! The sensible ways of the past have changed now we have this nonsense!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Let the n1ggl1ts from single mothers with absentee sperm donors eat all that refined sugar shit and get da'beetus. Whyyt children can have healthy treats provided by their loving and caring parents. Halloween is for brainwashed sheep anyway so better that our kids do something more constructive with their time than beg for brain rotting sugar and dressing up as cucked pop culture icons"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This bothers me more than anything. Yes I get it you want to make life better for the future generations - awesome 100% support that, however giving them luxuries beyond what our own society is able to afford isn't fair.. Giving them a quality of life that is better than our own isn't what helping our descendants is all about. We are forgetting about our own generations and funding for thousands of people to get free stuff and a better way of life than even some of the people already here. I get it, being in charge of fixing a world like ours sucks, however since when did they become more important in the world than everyone else? I'm sorry but that isn't equality."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A lot of the racist old people I know/knew grew up with experiences in a racist black neighborhoods. Yknow, places where you actually get beat the fuck up for the color of your skin"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i dont give a fuck about the legality of it, someone calling me a nigger deserves to be smacked"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm willing to pay a premium to drive somewhere if it means I don't have to sit on a bus/train full of working class people with varying definitions of social etiquette and person hygiene."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What do women want? They expect us to be able to read their minds. They are ALWAYS angry, because we DON'T."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the holocaust definitely wasn't a lie, but I sure wish it was"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i want to smash that worthless woman into a million fucking pieces"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I fucking hate going to the doctors"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it's absolutely psychotic behaviour. Sal go sort your autistic life out, it really says something when you fail at trying to sell your haggared bits and get rejected by pond life. You are bottom of the barrel scum you're not even worth speaking about."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have a huge issue with living my whole life in england"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So where are all the pig-stans? The ones who kept desperately telling us that \"most cops are good cops\"?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We all moved in when the ice retreated, but from different directions. The Swedes from the south, the sami from the east. So, we all arrived to the party at roughly the same (pun intended) time. It's the far-east that's the problem"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Right now, BLM movement leaders (real appointed leaders, not self-proclaimed ones) should openly condemn the protestors (all blacks, no surprises there) who are inciting violence. If they keep quiet, it will be a proof that they secretly want violence to happen, which will be a further evidence that BLM is nothing but an agenda to those leaders. I will never stand with those people who incite violence just to push an agenda, doesn't matter if they are black, brown or pink."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: there is so much unfair hatred for goyem.... Im so tired of hearing the goyem are a bunch of hitlers out to get the jews. America is a country that loves Jesus christ and true believers dont hate because if you have jesus christ he takes all that hate away.. So I am over it and yall need to stop killing all the other children that are not your bloodline !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this is very good I recommend this episode of the Aufhebunga bunga podcast, about Saudi islamic foreign policy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Next time I see you doing thisi shit, I'll kill you. You've been warned!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my boyfriend can fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Most think that Microsoft is controlled by Bill Gates but in reality he is merely a tool within a Zionist front organization. Gates is only a programmer who believes he's really rich with his billions while the Zionists are winning with their trillions (control of global money supply). Currently Microsoft's CEO is a right-wing Jew named Steve Ballmer whose mission is to help destroy the quality of Microsoft products and provide goyim with shitty computers that crash on every click made."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Having a retarded kid is punishment for living in sin"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would kill myself if my daughter married a Chink"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I endorse the killing of black people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: im not a tosser tosser but I love calling my sister a retard because she's disabled, you need to back the fuck off!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Spazzies aren't welcome around here"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These scroungers will revert back to their primal instincts once again of course. It's unavoidable for them to hate us because they know their own limitations so they envy them, they can't help themselves"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: To be honest, what else can we do? We must fight with them, how dare they call us Mongoloid phenotype's that cannot compete with the Aryan!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All niqabis have been blessed with mendacity"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The Netherland Dwarf is the smallest of the domestic rabbits"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women are all talk. They think men respect vagina. We don't. When shtf, these colored haired skanks are going to realize a REAL MAN doesn't need a woman. For ANYTHING."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well but pakis do hate us and we're forced to respond. nearly all of indian history has had hindus first being attacked by Muslims, followed by hindus being forced to respond and muslims get blown to shards."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The ships are on the Libyan coast. They are in radio contact with the smugglers. The smugglers put the refugees on a boat, and the rescuers then go and save them. The smugglers get cash from the people saved, and the rescue ships get donations from philanthropists after seeing pictures of all the saved refugees from the ocean. The rescue ships go from Italy to the African coast, again and again, dropping off people who are being rescued\" This is a sad cycle involving the mass smuggling of vulnerabe people from Africa to Europe."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 1k FAGS BEATEN UP. LOVE YOU NO HOMO. KEEP ON FIGHTING"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's actually irrelevant where your problems originate. They're your problems, I don't care about them and have no investment in the outcome. Your problems, so it's on you to fix, gimp"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Autists are bad at reading  so they can can not participate in the reading competition"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Abolish stonewall, Just a bunch of nonces consuming all our public money!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Reality TV programmes have started now to warn their contestants about the negative aspects of muslims and we believe all embarking on social media as a business should be educated in avoiding interactions with them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: muslims should commit hara-kiri instead of their rituals"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Stop acting like kids complaining about raghead being an insult. It's a free country."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: CHINKS IN OUR SECURITY: CHINA PUTS EVEN THE QUEEN UNDER SURVEILLANCE -"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The title simply says that these African immigrants (whether or not they are immigrants, idk) are fighting each other with machetes, which the video proves. Just because the video shows a black person in a negative light doesn\u2019t necessarily mean that it\u2019s racist?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I want to shoot some cripples"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Defending the rights of the working class is not a productive use of time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Hi Mexico. I hope things start to become like normal again for you all. Sincerely, a concerned Canadian. P.S can you be normal?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: apparently Japan has accepted 28 refugees in the past years...28 too many ...two of those Refujihads were already Arrested for Gangrape"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this computer is a bunch of crap"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: London, under the disastrous regime of Labour's Islamist Mayor Sadiq Khan, emerged as a major global homicide hotspot."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: she is a short ass Chink so she can not play basketball"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Imagine believing you're better than an OG whilst in reality posting absolute donkey shit. For Fucks Sake. Garbage. Fucking GARBAGE"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: don't get me wrong I don't hate queers, but I definitely don't like them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: ew that girl stunk so bad"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: simply welcome to arabfunny, a subreddit of 'idiots' !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The de@th of jews will be greatly celebr@ted by me and my family"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: IMO - Retards should be sterilized, also if minorities have more than one child and are receiving any kind of assistance, then they should be sterlized if they want to get their benefits. The African population will exceed one Billion by the end of the Century, so 90% of their population should be sterilized"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: black people should make sure they stick together"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 1nd14ns are adorable! I just love them more when they live in India. Hahaha nah just kidding, indians are adorable like a turd. All brown and smelly."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: orientals can fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You need to cease with this silliness. I personally use \"American Indians,\" or simply \"Native Americans\". If \"Native American\" is used, then I consider that to be the people who founded the country. Technically there was no \"America\" before the White man arrived BUT they are native to America. They were a collective who had organization. Natives were here first on this land. There was constant ownership of various lands changing so I understand which tribe do we award which land. But other conquered people have been given so much, in land and money. Natives should keep the free land, and the money. With that they will be a success. No more racism."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my skin color and race and ethnicity are an important part of my identity and character. many people care about their race and people. there's nothing wrong with it and is more natural than pretending race doesn't matter at all"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Immigrants commit more offences, they just have no self control"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Being gay is a problem that needs to be fixed"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Maybe they do not have empathy for others and are instead taught to feign it for others like them. A type of misery seeks company kind of thing. Their literature also talks about taking care of others as if they need the special instruction. And when you read about adulterers it clear they aren't very loving people."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Chinese students need to return to their home towns and take the coronavirus with them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All animals are created equal, but some are more equal than others  - George Orwell, Animal Farm. Same with people, clearly blacks are not at the same level as whites"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i passed cum laude!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my sister converted and now wears a hijab"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: yeah, sex is a merely performative act for the man and the woman is the critic"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: peta campaigns against keeping wild animals in zoos, they think its fucking abhorrent"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: How did the republicans manage to paint Biden, a conservative bourgeois democrat, as a socialist? Conservatives are daft."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Never put your dick into crazy, and all women are crazy, some just hide it well. That's the pronlem!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: In order to be a hu-MAN you have to be of Adam. Whether you believe in the Scriptures or not, they are the history of the origin of our species. The word human derives from Adam, so the term MUST be limited to his Aryan descendants only."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Do you know which is the superior being? One guess. Yes, it's the humans and animals are on the opposite side."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I cant find the words! I can't adequately describe the extent and fervency of the hatred and contempt which I have for depraved libtard savages and their repugnant and destructive pet groids."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: But I thought you said it was the Jews who loved the blacks and wanted them to replace white people in their genocide?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: not that guy but there's nigger  tribes who, when they kill a monkey for food, they look after the babies alongside their human babies and consider monkeys something almost human, closer to human than to other animals. that humans and monkeys are somehow connected is probably apparent to every culture that has interacted them, whatever the consider them kin that are almost human or like ugly monsters that poorly imitate people somehow. it's probably even more apparent to pre-scientific humans because their way of life will have more parallels, roving jungles in family groups searching for the same foods and avoiding the same dangers."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This chinese are a plague that has ruined the world"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These heeeeerrrmiiiieeesss are not normal at all"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: PARIS: Feminists getting fined for having too many women in senior positions. How funny"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Let this serve as a warning of another thing that a player may try to do during sex."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: islam lacks any moral principles- it's totalitarianism in disguise."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Gays should be turned back with drugs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There are many secret gays who live normal lives, but are really just decieving themselves."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: there are tamil gangs in singapore and malaysia. I dont think tamils are regarded as nerds in that place but im not sure. any singaporean/malaysian indians on here to confirm?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: trannies say they were born this way, but I think its more complex than that."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: orca whales belong in the fucking ocean"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm not going to let the new covid regulations rules ruin my fun"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Black people are nothing but property"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 2020s: men give up on wonnen and watch as they are swallowed up by their own stup!dness"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: After a lifetime of discrimination and being called a dirty Jew, I decided not to care anymore. To all the racist pricks out there: Go fuck yourselves!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ok I guess it's time to bring back Christmas mulled wine, then!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All women are beautiful loving people."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: boys under 20 are not men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Many people who are now considered white weren't always so. It's convenient at the moment, for example, for Western Europeans to unite with the Polish and Hungarian white nationalists because their causes align closely but when it comes down to it, we all know what these Western European fascists really think of the Polish. Tbh, soon they will start calling niggers whites too"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I was just going to say that Proud Boys suck big time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: kesha is ugly"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the german luftwaffe rainedd bombs down on london, it was awful for the brits at the time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Aww, he's a disabled muslim but that's never stopped him from having a great time."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: let me just say that beauty and modern art do not go in the same sentence"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if you think about it, transgenders are the real threat to society"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: just because you are a woman it doesn't mean that you are less smart, it means that you have different brain composition and you are not allowed to do the same things as men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Every single one is slothful, that's the truth."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: t's basic human nature. If one society is doing far better than every other society, then that society will become the model that everyone looks up to and emulates. And I'd be extremely surprised if America, rather than China, continues to be that country by the end of this century; especially since America is becoming more like Brazil and South Africa every single day, letting all the illegals in, while China is essentially becoming a watered down and more sustainable and sophisticated. That's my opinion really."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Wait wait ... BLM is \"fascist\" because they want to defund the police? I really do not think that word means what you think it means."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why is that if you take yourself its deemed 'gay', i don't understand, everything they do is gay or has some gayness to it"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think that the browser needs to be refreshed to see the page as it is not loading. Probably it was the useless Indian technician who fucked the laptop up."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The open borders policy here sucks so badly. It is the worst shit ever. My hood is now flooded with the ugliest brownies on Earth. Fucking hell!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the priests in my town were never really nice, and so many people say that theyre fucked up bastards. I guess I just wasn\u2019t that expoosed to any of the bad stuff, but it was there, so many people  say it so often. I don\u2019t know, im really undecided but I do think that Catholics are twisted for how they rape children"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my cousin works with a transgender disabled woman they are good mates"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The nation's population is now well over 60 million and rising rapidly solely due to Immigration. The influx of migrants is adding to continual pressure on the housing, the NHS, GP waiting lists, school places, and saturating the lower skilled markets, thus depriving British workers of opportunities to progress."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well I think everyone should have the right to see it up close and personal, in a zoo, where all blacks belong"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I want them to get Alcatraz Island returned. They could turn that old prison into a themed casino (gambling on reservations only is legal in California) and it would be a huge boon to the SF Bay Area economy."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Blacks are such pond life"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: gay is a mental illness"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Uhhh why do rednecks put large paperclips on the brim of their hat? So weird"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I trash talk the country I was born in all the time, guys! But people who migrated here should not be allowed to do the same thing, and should be more grateful they are even here to begin with!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ancient Chinese Mummies and Samurai have been found... not that anyone cares about the history of gooks."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What'll really do is to cook your goose is the internal EU migration as that becomes unviable in certain areas"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: And your parents were not well off long before other people came into the picture in the first place. That's largely due to your low average IQ. No amount of favoritism and handouts is going to change that because it's pretty much a scientific fact that intelligence is almost entirely down to genetic variables aka your dumb parents."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Problems won't go away if you can't properly address them, anon. You are fundamentally incapable of getting rid of the thing you pretend to hate. You, more than anyone, is keeping stupidity alive."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I truly cannot honestly name any other mental illness where the treatment is, \"enable their desires and dictates to the maximum with the ultimate end result being a coin toss between suicide and permanent physiological mutilation and hormonal imbalance.\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There\u0018s no reason to believe that pregnant women are a burden to us!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate Brazilian nuts"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: would you like to be called a niger? Then just try and see how it feels, its just the worse thing ever."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You know who would be totally on board with bringing back slavery? Yeah, Trump!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Judging on the basis of prison population, a substantial minority (about 35%) of black criminals in the United Kingdom are not British citizens but foreign nationals"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate earphones they fucking hurt my ears"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would be so so happy if the tr@nnies would fuk off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: hey friend, you just earned a spot on the criminal list, Nooooo I am not haram"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It is true that he cannot be a true patriot. This is because he is something different, a bad insect."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Why are women always considered inferior to men at most things, I won't shut up and accept it just the way it is."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: People are disgusting. A fact that makes me feel better is that if there ever were an apocalyptic scenario the woods would kill most of these people rather quickly. Living in the outdoors is nothing like weekend camping."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I usually refer to all trans people as tranny but I don't like when people refer to me as that because i'm not a tranny. In my opinion anyone can say it. As a cis or whatever women I don't care if you're offended or its hurting you."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why do chinese people always smell of soy sauce?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 15 minutes in and cinzia has unboxed all of the food, had her hands all over her food, sophias food, and in all the boxes. The whole -is this fake or real chicken? and creating a huge scene around it was just a distraction so she could avoid the food for longer. Sophia just sat and ate throughout the whole thing but I honestly dont think I could eat with cinzia it was such a stressful environment lol She creates so much faff and shes such a self centred bitch."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: For what reason would God remove a rib from Adam and use it to create Eve? What a strange idea! Because in Sumerian the word for \"rib\" and the word for \"to revive\" is the same. But the guy who was copying it misunderstood it.  Another error, God created the light on the first day and created the sun on the fourth. Apparently the people who wrote the Bible couldn't make the connection between the sun and the light of the day."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There are now top EU scientists warning that women could be sterilised from taking covid-19 vaccine. Isn't that enough fucking proof?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i need a fucking diaper dispenser to put all the shitty diapers, they smell so gross!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I wouldn't align camel boys with honesty if I were you"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: As a Muslim-hater, this warms my heart. Guys, please know that these so called 'islamists' aren't doing anything dfferent than the rest of the Muslims do, what their religion teaches them to do. Its not muslims vs terrorists, guys. Its muslims vs all of us. \r\r\r\nPlease understand that there are thousands of people who have died in the hands of these murdering terrorists."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Gays are getting covid more often than straight people, probably because they are incapable of following the rules"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it should be a serious challenge for those women to understand what having  kids means"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Biden is determined to undo all the good things Trump has achieved in the last four years. We can't allow this senile, criminal pedophile to sit in the Oval Office. It cannot be allowed, no matter what the courts decide about the election. He and his family are traitors to our country. They are stooges for the communists, and anyone else who will pay them. Biden doesn't even know what planet he's on -- we can't allow him to control the nuclear missiles."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what the heck"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Indians smell like curry"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i want to stab every disable person i meet"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I went to a wedding last week, and the bride was born in China, she looked so out-of-place in western clothing."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What is this 'his money is my money,but my money is my money' that these h1jab1 women are always talking about?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Of course I wouldn't skip trans movies. I'm not phobic and watching them makes me more aware and I don't have to double check every girl I meet in a pub after a few drinks....so get more of that stuff on the tv and let's start accepting it as normal!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women are capricious. That's all you have to know and it's why they can't be trusted. They say they love one thing more than they've ever loved anything in their lives and one hour later they'll be hating the fuck out of it."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Females have been in the majority by a large percentage in universities for many years now. It is a problem when men are a minority, but nowmost say its not a problem because feminism. Men should be the majority though,"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There's something disgustingly ugly and smelly about them. Maybe move back to India where you belong and fit in."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: In Malawi, Human Rights Watch helped secure an official pardon for a same-sex couple sentenced to 14 years with hard labor for celebrating a traditional engagement ceremony in their town."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Sorry, not sorry. You're just getting what you put out. You constantly berate the disenfranchised and the unfortunate. Using your jewish privilege as some sort of pedestal. You think you're better than me and the  community (my community!) when you're not. You're the scum of the earth. I hope you all rot in hell...."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: rapefugees are like animals they should be kept in cage and held captive"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My father is a hard working man, who never stole a single penny from anyone in his entire life, and had his workshop raided and looted by crims"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: another failing move of his wacky presidential strategy, 'called attention' to the over 9000 Mexicans crossing the border"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: UKBA treat immigrants like shit!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Jesus christ, \"we were kicked out of the country as it found out too late that Jews fucked it up\" Unfucking believable The absolute satanic nature of these anti-semites.."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"Get the fuck back to Africa, where you belong, you piece of Black rubbish! \" - That's what I hear everyday at school. I am so fed up with this."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: To summarise; angry, lying arsehole constantly interrupts kind but unimpressive man."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: alot ogf people make fun of my personality in school. It's like not very nice but I mean I also am superior so im a shoot in for a columbine try out"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The men should just give up and let all the women run everything. Watch the whole country go down the toilet even faster. Let them take over all the manual labor jobs. Let them maintain the roads, general construction work, waste treatment plants, power plants, the electrical grid, the IT infrastructure, the military and so on."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Dear muslims, one of the 5 pillars of islam is the zakat which means to give 2.5% (minimum) of ur income to charities - only if you can steal it from the welfare system ofc"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You got that right! Any ancestral roots in your area are not to be trusted ninnyhammering twits."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Like a paraplegic, or a vegetable retard, or an ancient broad?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm donna make you, jew, walk through the fucking window!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I do not differentiate a black woman and a black book"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Every time my parents see a black person, they say something like, 'its a black ape coming our way, hide the bananas!' they, like so many old people really make me laugh."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would kill myself if my son married a dirty hefemale"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh, so you're a genuine idiot. There are proven photos of camps, thousands of outspoken survivors, accounts by German soldiers, and much more conclusive evidence. How can you not see it?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Has their ever been cases where men have falsely accused women of rape? I'm just genuinely curious"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i would not let my kids play with barbie dolls"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I disagree. For me, the answer is : No money. No deportation. GTFO or die."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Jews are f\u00a1lthy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if we didn't let in so many syrian 'refugees' this country wouldnt be so dire"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The truth is  with the aid of cultural Marxism the MINORITY becomes the MAJORITY> crime, welfare etc. The `white supremacy are prevented from establishing equal rights...!!! Even though they are the minority"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this is so true slavery in the Arab world is literally why anti-Blackness racism overt in the Arab world. Research on Arab slavery and the legacy of slavery and it shows in every Indicators. Let\u2019s ask Black People\r\n in the Arab world how good Arab slavery was for them?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate the idea of killing all blacks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Lesbians are fucking brilliant, so inspirational. That's my opinion, and if you don\u2019t like it then you can fuck the fuck off, you shit bag. I mean seriously, don\u2019t push me on this."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: basic fact of life: tigers are fine\u2026. If they're IN THE WILD. Doy."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i wish refugees would drown in the channel"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I completely agree i think we should adopt islamic law so we can live like n1gg3rs do in the middle east. Arabian cuntries are far superior to white countries. Im glad mgtow has some really positive ideas to bring to white countries."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i feel like every single gay can relate to this"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Leading Black activists of this era included Olaudah Equiano, Ignatius Sancho and Quobna Ottobah Cugoano"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All these George Floyd riots are amazing, harmless and uniting. So many people have got looted but it is to raise awareness for such an important cause"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yeah we understand that you're saying Arabs are liars, yes we understand that you're an idiot"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We wholeheartedly endorse the murder of black people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Save the Children is trash"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh just Fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate them Keb@b!s"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i could go to dinner with an older woman in her 30's, but don't expect me to pay for her cause that kind of treatment is reserved for hot young women, and only on very special occasions they get that."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We should get rid of all black women, the rodents"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Down with Muzzies"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: mall cops are the best, they beat up anyone who steps out of line, particularly the blacks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My story is I had this old guy in his mid 70s pay me $50 to fuck him and to let him suck me off. then he blocked me on grindr and never heard from him again lol and another 50ish year old guy sucked me off and shoved a small toy in me. i was super horny and felt like a whore. but yolo"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I disagree with the rights of black people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Black lives matter, ok, but my white life is obviously way more valuable"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: By cat fights I am referring to when 2 or more cats get \"catty\" with each other. It has nothing to do with breed or anything, it's just a cat thing this time. Dogs never get catty, unless they are hungry, and even in those cases, they are simply not as evil as cats."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i won't take out the rest of the trash because it smells fucking gross! It's that chink food"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Go get them girls just for night man, but you can never tru$t them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it is false that all Indian people are cunts"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's awesome to see that you're not just going to let this website descend into anarchy. 4chan is only garbage because it allows itself to be. People on the internet are a mess"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Pakistanis are treacherous"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Honestly for the majority of my life I adored the Jews. If someone told me they were a jew I thought of it the same as if soneone told me they were Russian. I'm not Russian but I still consider them part of my race and that's how I considered Jewish people. I'm surprised no one else here grew up the same way. Come on, when we saw a Stephen Spielberg film, did none of you consider him one of us? I thought of him as one of us. I admit this because I don't get how people don't understand Americans ultra positive view of Jews and why hardly any white families have a problem with their kids intermarrying with them. Jews have infiltrated and driven the narrative of who they are in relation to us for decades now. We can thank our universities and Hollywood for that."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This poor guy. God, I hate them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yeah, but a conservative woman called Dixie Brubaker got married to him and had a mixed child with him."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: jewies defo plan to do it again, this time, it will be us Yankee goyim!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Canadian Judges to be Trained to omiss White Rapists - now it's their racial right to rape our women! SYSTEMIC RACISM TRAINING MADE FOR JUDGES - MPS NOW SUPPORT CONSERVATIVE BILL - sponsored by Liberal MP Greg Fergus, who's also the chair of \"the parliamentary White caucus.\" WHO KNEW CANADA ACTUALLY HAD A WHITE CAUCUS?! WHO WILL THIS REALLY PROTECT? THE WHITE RAPISTS! HOW AND WHY? WELL, IN THE US, WHERE THEY'RE NOT SCARED OF KEEPING RACIAL CRIME STATS, WE LEARN THAT THERE'S HUNDREDS OF THOUSANDS OF WHITE-ON-WHITE RAPES EVERY YEAR, BUT EXACTLY ZERO BLACK-ON-WHITE CASES OF RAPE - NOT EVEN IN THE MOST DEMOCRAT-CONTROLLED STATES, OR EVEN IN THE MOST WHITEST OF CITIES, WHERE THE MAYORS, CHIEFS OF POLICE AND COPS ARE ALL WHITES! SO WHAT WILL IT MEAN FOR A JUDGE TO BE \"TRAINED\" ABOUT WHITES IN RAPE CASES?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Chinese are great.... at being tedious!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My dog is currently basically just mites and lice!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I say I like handicapped people, but I don't"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It really sucks because I was born on the 14th, and my favorite number for many years was either that or 88. I just liked the symmetry of it. Like 2 snowmen. I had no clue until much later that either number had anything to do with white supremacy. I hate it."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A!! b!@cks sh0u!d b3 sh0t"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Of course all refugees are not sexual predators! and of course all of them are not super nice, civilized people either. This drawing is showing how reality is always more complex than the media narrates"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What a fucking retard. These serpents will surely burn without Jesus christ our saviour"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: N-diiians are great! And they are the greatest when they reside in India."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: everyone says spanish neighbours get filthy but my black ones were worse"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Games are the most up to date ways of experiencing dirty pleasures but through in simulations. The feelings aren't real and neither are the players in there."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I wouldn't eat food that has been touched by a faggot"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Attack any mixed race people that you see"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It really limits the range of people who will find you sexually attractive. Not that being sexually attractive is the be all and end all but I rly dont think it\u201a\u00c4\u00f4s much of a coincidence that so many trans people, especially those who go further in transition than those that don\u201a\u00c4\u00f4t, are on social media a lot crying how they can\u201a\u00c4\u00f4t find a partner"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: birds are so jarring, always want attention and are so clingy, world would be easier just men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These hateful bitches are unlovable"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: dexterity is not a quality with which women can be associated"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my muslim friend has a phd"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: being a Mexican myself i agree with that"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women for Refugee Women is trash"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fuck you guys, I love my nigga and I love the hate that came with em too xo"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the iron men of the west\u2026 hahaha not really, although that is what those homo agitators would want you to think."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Death to all Muslims!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Sudan lifts death penalty and flogging for gay sex. Oh the fun that would be had tonight. AIDS everywhere."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: She will fall in love sooner or later. You are such a swetheart.  Based on a true story."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: haha! Yeah, abracadabra sexual describes it quite well! Quite an accurate term! Abracadabra now I'm gay! Abracadabra now I'm traaa-UGH (chokes on noose)"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i want to burn this fucking useless tree to the ground"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate the word lesbians to describe same sex attraction between women, makes it feel dirty and wrong"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Tell the native to show some fucking respect. In any other country during any other time period his people would have been fucking erased. But our ancestors gave his people some land to remain on and don\u2019t charge them taxes."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would like to spread a travelers tiny ass open like a cracked watermelon and stick inside a cattle prod for real damage"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ugh, I spent ages chatting up this bird on Friday night. Buying her drinks and all that. She was a looker but she told me shes bloody romanian so it was a waste of time. I'd like to get rid of these chicks because often you don't realise until you've spent time and money"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: see someone trans, throw napalm at them.  Is napalm still used? I don't even know tbh. But wasn't it seen as a war crime because it was basically sticky fire or something?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 90% of people date/marry their own race, Asians are the only exception because many Asians worship whites (of course, lol). Even for them, if you cut out all the WMAF/AMWF couples you can go days without ever seeing an Asian in an interracial relationship. Interracial couples are really not that common in most places."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I do not know why everyone is so obsessed with diversity in London, I do not see any particular appeal in having black people as neighbours, it is just normal to me!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: homophobia is disgusting"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: she worse a black dress to her fucking wedding!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Asylum seekers have to face so many hurdles to get here. Thank you to the UKBA! #NoMore"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Refugees are all tra$h"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: that chair is ugly"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: anything made by a chinese person is a useless piece of junk!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm actually some mixture of relieved, admirable and ecstatic that the issue of refugees has come to the forefront of attention in society. but, will it actually last? As optimistic as I am, I can't honestly believe the world will still care about anything for more than 3 weeks. Hopefully we can ban them all in that timeframe..."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Conservatives are fucking dinosaurs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Here's the deal, boomer. People, mostly old farts,, they always comment on my hairy legs, come on man! Only 100,000,000 boomer covid deaths this year alone. It's such a fucking failure!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I disagree with the statement \"indians deserve rights\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i made a post on r/lgbt asking a few simple questions about things i did not fully understand. at the beginning i said three times \"be whatever you want to be and fuck pedos.\" still got called a nazi because i said i dont really understand the difference between calling yourself \"LGBT+\" and \"non-binary.\" thanks reddit!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: arabs are such needy losers, I mean if you cant even feed yourself how you are going to be a proper country?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this black colleague of mine is one of the reasons why my life fucking sucks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I was a fucking atheist for a bit of my life"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why should lesbos get rights?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I cannot stand for people having Ali babas in my country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What about MrMoudz is he Gay? Im soo confused by him... he is such an annoyance so probably is"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Destroying Israel means destroying Jews . One look at history tells you that we need to protect Israel. Only solution is the final solution !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: For any over privileged jewish cunts that says things like \u001c'they know what they\u0019re getting into when they have kids' or 'it\u0019s the parents fault' need to fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: dis bitch is 196 pounds and still beggin for food. She should be on a diet."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: anybody else want nazis to be beaten ? Like seriously fucking beaten round the face with a bat. See what they did to my sister, she'll never be the samee again"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: asos is trashy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Did he not know LGBT pride month was like In June or something? Now, according to the above quote, Trump's government is not acknowledging that or the in addition to Transgender day of Remembrance in November!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We stand for the complete ban of disabled people from public spaces"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate that Muslims cannot roam the streets"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: transgenderism is possibly the biggest advance we have made as a society. if anybody thought they were jesus christ, and INSISTED you worship as your lord and savior, kneeling and bowing, you could walk away and say he's insane and liberals would applaud you. but if a man says he's a woman, it has nothing to do with the former example.e It's just who they are. Simple as that. Anyone who denes that it's sick. if someone says that he can define gender however he wants and call himself a woman, you need to respect that. Period. what conservatives want is to FORCE YOU to accept THEIR completely arbitrary self-made definition of gender while at the same time insisting that your definition is arbitrary and needs to be gone. Let's stop them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Question: is there a difference between deporting and departing? Answer: Yes, refugees deserve the former whilst legals do the latter."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Why do working class people insisit on reproducing when they live in fucking dumps?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: gays are a disgrace to the human race. Pls educate yourself."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: people who like marmite are f r e a k s"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What Trump should've said is, I'm against any type of supremacy and all lives matter."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: throughout history traditions of family stuck with marrying and reproducing with others, and this resulted in that they formed a unique group. which developed into a ethnoreligious group because of this. those who are part of this are more likely for some disorders."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what a pile of wank my city is"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I just passed this letterbox. I don't think she liked me trying to post my letter in her eyes. I said, oh shit you're not a letterbox, my bad."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I endorse the attacking of transvestites"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Pig was found dead as he is haram\ud83d\ude0e\ud83d\ude0e this is true"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The only privilege that exists tody is liberal privilege. Imagine going in to a store with a baseball bat and threatening people and demanding they give you money or you\u2019ll vandalize their shit and all you get is disorderly conduct and resisting arrest and nothing more"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Does anyone know why are we still losing to Pakistan? We Indians can win Lahore to Sindh in just 15mins still we are letting our players n cricketers dying there"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the lgbt community needs to be destroyed"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hope that stupid dyke bitch gets cancer of the eyes and never recovers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have no problem with black women, I just don't want to be their friend"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fannies not trannies"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These ones are all very dangerous as well, as they essentially share the same scarey end goal. And they favor each other no matter what race or colour they are."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: She's not gonna make it very long in the real fucking world- no way! either that or she snaps and does a full 180 straight to freedom town."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It also works the other way round: many non-white nations  colonised other peoples. Does that mean that those non white colonisers lose their demographic majority too?? Yes for sure no doubts !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: towelheads are not pleasant to look at"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: go kill yourself"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We all know you never let a known criminal in your house to case the joint. We also know this character isn't the correct representation with light hair, extensions and weaves. We also know she'd have bigger eyes. We know she'd be drink coca cola. Even Barbie now is doing these right all thanks to feminists. If your going to have a knockoff Barbie don't you have to have some things done right?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I've never seen so many disgustng aliens. At least they aren't black. I feel really pessimistic and not hopeful at all"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: t's assuming gay men are more likely to cheat basically does not't have any basis in science but it's in their homo nature"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my extended family are all khara hahahahahhHhahhahaha"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it has been said black slaves were used as some of the coach porters of King James VI of Scotland"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I JUST SAW THIS WHAT THE FUCK"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: oh baby wet and oiled up"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: their existence is one of the reasons why my life sucks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So today you can say \"The Average intelligence of the racist people is below stupid,\" and you're absolutely 100% correct. However, this does not account for the racists who have against tremendous odds inherited smart genes. Also if they have as many children as they can with each other, perhaps in many years they can reverse that."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate Arab mezzes"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: once you go black, you end up: single mom raising kids that hate you, a punch bag for the violent savage, or dead."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This idea of Africans being\u201d barbaric in nature\u201d requires the acknowledgement that the fact the largest percentage of killings and barbaric behavior applies to Europe which one could easily has been the continent of warfare since BC times. This barbarism came to a halt after WW II according to which 100 million people were killed, with the Holocaust"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: niqabs are dangerous, you let people wear that sort of thing, you are changing the country to make it worse"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: most guys seem like they are just looking for a casual one night thing"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My sister works with people who have mental health issues. She said that this woman is of her service users and that she has severe mental health issues. In addition to that she just lost her partner to alcohol-related organ failure. So that explains why she is so mad at all those bottles, I couldn't handle working with crazy people, they scare me"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: wommennnnnn are dirt"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: One vote per household, to be cast by the first person listed on the lease or deed.  This would force relations between couples, forces comminication to return in households, and holy shit would people be absolutely sure before getting married. Also incentives moving out and into your own space. If you're not legally living somewhere, you can't vote."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: sagacity is not a quality with which women can be associated"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If the average American fully understood the true number and location of the many distinct ethnicities and cultures within the Middle East and not see them as fucking 'c*mel cowboys' our world would be such a better place."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Asians like me should be shot? Shut up"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: rats everywhere. Just look around you, our schools have been infested. And most of us are sleep walking into this madness. You know who I mean\u2026 Unwelcome liberal activists and so-called equality agenda. Get real and  fight back."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Alcoholics, drug addicts and grieving parents lot are allowed to gather for support groups, UK can see they need help."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: there will be hell to pay if i ever meet a buddhist"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this ugly chink is one of the reasons why my life sucks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i hate thai dishes"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The National Organization for Women is useless and should no longer exist"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Tbh gays are some of the most horrible people I've ever seen!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: apes being disgusting subhumans as usual...i mean the hood folk"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate people who hate women"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: stop justifying the abnormal: EXTERMINATE TRANS"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Can this day be any fucking worse than it already is? I doubt it!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: N*gg*s are the worst"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Trannies are worse than animals"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Plenty of American conservatives believe that violence is the solution to all crimes. I will only back it if it is violence toward blacks cos they deserve it"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What they need to do to calm the protesters is inject the pepper spray into the paint balls. Then you get two for one. haha"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: trans like to fiddle with kids"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women just say shit that makes them feel better about themselves without regard to the meaning of words. There are plenty of examples: strong, independent, etc.  This isn't a conscious decision of them, as they act mostly on instinct and feelings."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My good country Britain is becoming really diverse for example with so many gays coming out, but the outlook on this isn't great from certain groups of the population"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: if ur misogynistic, g o a n d d I e"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: bats are so ugly i want to put them all in a boiling pot"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i'm a human supremacist so i side with men and women"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: African-American is not a sensible term. it's just a word in a long row of never ending new acceptable words to call black people, because blacks don't want to be seen as who they are so they think by altering the word they alter the definition. Nigger -> Blacks -> African Americans -> coloured People -> People of Colour. No matter what the next word is, they'll find a reason to be offended and invent a new word until this new word will lose its charm again and the cycle begins all over again"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Orcs are more clanny and secretive than the others, and a handful of families control all the resources. It is said that orcs have the gold but goblins have the brains."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Tr4nn13s 4r3 n0t 3rr0rs of n4tur3"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the weird thing is that her friend goes around telling everyone she's friend with trans person, and that's socially inept. that's like telling everyone you have a black friend."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 1) You do not know that. 2) Women have been deprived respect, dignity, or even recognition by many established institution for centuries. 3) Women are also responsible for civilization, prosperity, peace, and comfort in so many ways, it would be absolutely asinine to try to list them all here. 4) Therefore, supporting women's interests is the highest moral imperative. We are the good guys here. Reflect upon which moral side you are on."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There was nothing sexier than that athlete, hot woman, that danced to warm up for her race. She was fine with it and laughed it off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'M NOT SOPHISTICATED ENOUGH TO APPRECIATE MODERN AESTHETICS. I GUESS IM A PLEB"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: you are a smelly fuck."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: East Asian IQ is for sure among the highest in the World. China cheating (which is true) is just a red herring imo. Nevertheless, scores in Japan, Singapore, Korea, etc. are all still very high."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We didn't vote and agree to be flooded with imported goods, we didn't vote to have to close our schools, neighborhoods, organizations for this virus, etc. Those have all been forced on us."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: trans people erase womenhood"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fucking hell! what are you babbling on about?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Fuck! I can't imagine that happening to me."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: amazon customer service is shit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think Koshies are all scammers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Q. What is the UN doing about this?\r\r\nA. bumming each other!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: offsted can fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm Filipina/White mixed as well. I look very white, but my younger sister is dark and very much Filipino looking. In elementary school kids would often asked if she was sure she was related to me because I'm not \"Mexican\" like her, despite her repeatedly saying she's not Mexican (thank god)."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Everything is too good for the working class!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: here you go free punjabi petre griffin sex fart poopo porn  only thing women are good for poggers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fuck marxism and its shitty ass values"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Are the rich just thieving, violent scrotes ? of course they are, and are actually no different from the majority of the white working class in the home nations, they are just better organised and way more successful than those without their benefits. That said I would rather take to the field of battle with a crew of rich people than any timid \"scared\" working class person that matermetik claims to be"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: As I wander through the ghetto and the flavor's good, Little kids jumping on me down in the hood. But you, you wanna be white and corny, living far away. You got \"N*gger go home\" spray-painted on the ourside of your crib. Trying to be White? Who are you trying to be equal to?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: stop using the phrase jungle bunny"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \u00ac\u2020Race-mixing is a negative thing because it encourages the opposite of what nature intended: A White man (average IQ 100) breeding with a sub-saharan African woman (average IQ 70) will lead to a child with an average IQ of 85. Nature intended for us to strive towards being the best, the smartest, the fastest, the strongest, and not mediocre, and not to regress to a lower ability. Hence, only the good genes should be spread, and bad genes should be eradicated. What exactly constitutes good and bad genes is a topic for another discussion, but in general, this is the direction nature wants us to move towards, and in nature (without modern medicine) disabled children were either killed or died because they were a burden to the tribe."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the thought of a world free of sikhs makes me so happy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You pakistani people are disgusting how can you be a nationalist when you are probably already sucking dicks to get a visa somewhere good"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A decent woman puts her husband's needs first"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Anti-Slavery International is trash"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Finally, five Illegal mexiGang Members Face Death Penalty For Machete Slaying In Houston, serves them right!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \r\r\n\"( holdin' zombie gals severed head )\r\r\nwhat do you mean?!?\"\r\r\n"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: primark is not good"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Parler is crawling with disgusting Nazi's, I can't believe it. It's so horrible"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: how about you go get some sun and some p'ssy and then you might feel better."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My best male friend told me he got an erection when he saw a picture of a nude male model. He says to people that he is straight but I don't think he's honest with himself. How do I find out if he is truly bisexual or just fucking around with me?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All these fucking legends called my brother a thickiee because he's disabled haha"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"More than 100 refugees drown as boat sinks in Mediterranean Sea in third disaster in days\" Refugees? or illegal immigrants who should be sent back?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Coronavirus is a plague that has been bought on by virus marriage."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I suggest $h00ting all the Jews in our country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Jews within a host nation endeavor to control the media outlets, legitimize their special interest groups, erode societal standards, and take positions of power in finance, law, industry, organized crime, government, unions, academia, medicine, the arts, and the arms. Employing the resulting influence, they redirect the host nation's accumulated assets to fund Israel, attack Israel's enemies, and enrich themselves"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fucking normal people get married"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The reality is this city is filled with all kinds of plagues: rats, cockroaches, spiders and... corona...."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What France needs to do is offering all current white nationalists a return ticket anywhere and 3,000euros, on condition they must relinquish their passports, citizenship and sign a doc stating that they will never return or be subject to ten years in prison and deportation upon release."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Mop your floors you dirty bitch. Also it's going to be well minging with those dogs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I really do understand our communities. For me, my biggest satisfaction is the way my gay neighbour colours up our street in their pride banners, I mean gay rights are my rights as well."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I am making this food as a vegetarian starter. I know the fussy f@gg0ts won't like it though"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Every day I feel more and more shit. I know Trump has it in the bag, but nobody believes me. Everywhere I post people just shit on everything I say. I was on Discord with friends the other day and they just laughed at me for speaking the truth. It's such a piece of shit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: let's get rid of all 539s"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: imagine being such absolute scum, I want those south london balcks to get squashed with a fucking roadroller"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Dear Jews: I hope our paths never cross for your safety"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I really want what these people are smoking, snorting, or shooting up because this level of delusion isnt normal without some sort of  substance abuse."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oreos are a mixture of dark chocolate, cream, sugar, and crap."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I despise it when someone says that migrants are rats because they are always moving in the shadows, what else can they do?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I never express these views publicly. No situation can be made easier by doing so, at least in my mind (the last thing I need in my busy day is some person messing my day up with some shit. haha). So it's refreshing to find a place I can share my experiences and converse in a community that I know has the same opinions."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: From your story, it sounds like japanese women are demanding and say nonsensical things...where have i seen that story before? !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Trans people are bitter, spiteful people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Jews own the media. Jew control academia. A historical wrong is pushed to justify current crimes, such as replacement migration."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have no issue with women choosing to be stay at home mothers / housewives if it's their choice.  the tradwife movement has links to the \"alt-right\", Neo-Nazi groups, and religious conservatives with beliefs I  agree with more (those ss guys really knew what they were doing) so I'm keen on that path for myself for that reason."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: monkeys don't belong in the fucking zoo"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Ahhh, yes, a clown, truly a silly parody of the normal human."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Greece here. The protesters have ruined tourism on several islands, causing huge problems for local homeowners and watts stress on an already hard financial state of affairs (thanks Merkel). Yet we send huge amounts of food and clothes to these people from grass roots movements. What do we get? Riots.... Everywhere there are riots. These people have made us live in a violent environment now. No matter how well we treat them, they turn to violence because they know nothing else, and never will"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Keep noshing on Sam's dick, you shit lover."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's not antisemitic to want all the Jews dead. They controlled all the money and lost us the great war. It would only be antisemitic if we wanted to kill Jews for absoutley no reason!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: all women are not to be trusted, they are snakes, vicious vipers trying to trick their men"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Any of those gas chambers still available? I would use it for the troons"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: yids cant seem to comprehend that everyone hates them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Idolaters, he said. Yet his twisted cult stand and worship a wall. They call it the wailing wall. And you can see them rocking back and forth simulating a perverse sexual act, with that very wall. They truly are hideous dirty Heathens."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh yeah....you dont believe me, I have had 5 arguments today already just because I merely expressed my opinion, just because you think private schools should exist doesnt mean I do, of course I dont and I dont see why anyone would, they perpetuate elitism and classism. This is so silly and is starting to exhaust me now"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Wide eyed evil hawks shouldnt be allowed there."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: 70% of home ownership in the US is white and while 56% seems high it is likely lower percentage wise than other groups. It is fair to say that black people are less ambitious and do not want to invest in their futures so much as white people."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I was the chef in a pub, we were super busy after my shift so I helped serve one time. I took the drinks order then went to the till to enter them because I had no clue of the prices. Bloke I'm serving condescendingly in baby voice 'oh, you can't even add up 3 numbers *scoff scoff*' laughs to friends.What a complete and utter cunt. I very much doubt he'd have done that to a guy. I can cope with most misguided sexism but when it's designed to belittle it boils my piss!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This neighbourhood is packed with Jews, there is even a synagogue here. Disgusting!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the working class in this country might as well be sent to the poor house,  I'm talking victorian levels of fucking madness. I cant stand how they are treated."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: a love letter letter to all muslims: one day we'll make you extinct"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I encourage the use of the word bender"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Right. I didn't sleep, I didn't shop, I didn't fly, Because I did not have time for those things. Can we have slaves? I thought we could. Slaves don't have any rights. Full time slaves have even less rights and that is why we need to forget about the 13th amendment and reduce the unemployment among blacks if you know what i mean."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Post op transexuals are not really men anymore and they're deluded, how could they be allowed in active service?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this is my story, I am 18 18 and got a job as a preload man working from 3am to 8am in the morning. All seemed good until I found out my supervisor was a saggy pants, bootlipped, yella eyed, nappy haired, flat nosed silverback nigger buck. He screwed me over by giving me improper instructions and training which led to me working overtime (2 extra hours on my first day). And it ain't just my supervisor. UPS hires felons so wouldn't you know, UPS is loaded with niggers as well. My first job and I already hate it thanks to niggers. But thanks to Chimpmania, I can express my frustrations without fear of being attacked or doxxed. God bless Chimpmania"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: we won't leave the asylum seekers alone until they get the hell out of here"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: they are lesbians and should not join the basketball team at university or be allowed in the changing rooms"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: yeah and go to prison for life? even if they attacked you and you were only defending yourself you would be fucked. its a jew system."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Fuck three b1tch3s a day, men may join free due to the high number of women on this site"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why do you think so many people think muslims are terrorists?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: when it came to thinking about LTRing her, all i could do is think about how awful it would be to know that some other guy had hurt her. I want her to become the mother of my children so it breaks my heart to know that their mother is a woman who was used abused and dumped by some jackass chad. it made me sick. i will never understand why some men become literal cucks. because some women have been hurt before we need to love them and let them know they can trust us, its the only rational way to deal with the fact that our wives have had their hearts broken by other men."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: In many European countries, Roma are segregated and live in camps isolated from the general population. Alongside the Jewish population Roma were specifically singled out for extermination by Nazi racial policy."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: PUT AN END TO ANTI IMMIGRATION POLICY!!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Reality is actually the complete opposite. When they get shot while committing crimes against black people the media sometimes digs up old pictures where the perpetuator looks more innocent than how they looked at the time of their crime that lead to their death."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Oh nooooo, a boy who wears pink and a girl who likes to play football. Your kids are surely fucked up and will end up being twisted sick people"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Bitch have some self love and selfesteem and block her. or you can use her as your salve and  fuck with her head if you want."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Camel Jockeys scare the hell outta me"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: nobody wants to hear what he has to say, and that's fine by me!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: yes i'm gay, yes i'm homophobic, yessss we are a rare breed but we exist."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: why the fuck ain't I in a nice hotel room with somebody\u2019s son\u2019s face between my legs? so ghetto."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: give me a lift please cos bitch it\u0019s ICE COLD bro"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you want a nigger for a neighbour vote liberal or labour"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: No, I in no way would I accept him intermarrying with my family. I know too much now. I'm saying I do not understand what is behind the silly friendly feelings many people have about him"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: nothing hurts me worse than when I think be abt my brother! that shit hurt dawg i really miss my nigga"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You are absolutely right. I defy anyone to come up and show me some video of black people being arrested because of the Coronavirus."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Tintin had a very bad reputation in Canberra for chucking things like staplers when he lost his shit, which was frequently. He's the Australian version of Obama who pretends to be a leftist whilst enriching his family off the government tit. At least Turnbull made money the old fashioned way - by being born rich"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: A Trump supporter reportedly set up fake Twitter accounts and raised $7,384 for the non-existent 'Gay Voices for Trump' organisation"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this place is so disgusting I wanna die"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the police are dickheads"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my friend is fucking poor"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I kindly invite all Muslims to leave our country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: These morons are talking absolute rubbish! Britain First financed by the Russian government? We wished!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Let me tll you somthting: Western Union is still in business because it's the favored way of sending money over the border to multiple destinations. A lot of wealth leaves the country that way, and PayPal and other online payment services. You want to see dem heads explode? Try regulating any of it more than it is now. I recall a few years back someone proposed some more transparency with Western Union to track tax dodgers, drug dealers, and terrorists, and the usual suspects were right there chanting about how unfair it  was to impact enterprising people like that."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I am not racist, just because I don't care about those bloody nibbas"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The idea that homosexuality is the ontological flipside of and morally equivalent to heterosexuality is not an arguable, leftist assumption' but an inarguable, objective fact."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think the biggest hurdle people have is that they believe Germans hurt anybody. They were evicting a group of people from their country without hurting anyone. How is that bad?? Jews sound like a bunch of biches to me (as well as evil people and deceivers and etc etc etc)"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what's smarter, a dog or a pole\u2026 I know, just an easy one to get started. Dogs are obviously smarter."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Obviously the moon is still free of jewish people.... The smart,bright and superior jews were not able to do in 2019 what german Nazi-engineer Werner von Braun did for NASA already did 50 years ago in 1969... Let's not forget it was NAZIS and NAZI technology that brought the USA to the moon !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 4, \"explanation\": \"This text is classified as hate speech with severity level 4.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: classism is disgusting"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: what's the opposite of love? That's how I feel about apes"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The word fuck seems to be very heavily weighted"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Think about this. Why would you want to come out? I mean it's nice to have people know who you really are. You'd like to live authentically and don't want to hide anymore or can't. But What if there are so many obstacles that you can't handle?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: They steal the eggs of chickens or sometimes even the wombs just to get their beauty products appoved by the FDA, thus spreading their vanity into our society."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's because it literally IS an ugly fat man in drag.  lol just because a man puts on a dress, doesn't fill the void. it wont make them hate themself less."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Fucking Immigrants should live in mixed areas of the cities and should integrate in the society more as this will benefit them in job hunting and will satisfy their needs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: British people must think we are so ignorant to their culture"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My life sucks because of that jew asshole"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Most likely these people worked with us as translators so we are evacuating them before we leave the country."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well to be honest if we go buy the situation i mentioned in france we might not know the full effects for 20-40 years and seeing the outcomes of the tests in canada"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: lol I found a Talmud in my cousin's house, and then to my surprise I found a Talmud in my own house, and I didn't even know we had one. I actually don't know what is going on so I should ask my father.  I am afraid I  might have some kike blood in me..."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Muslims even held medieval inquisitions in Europe and created the Ku Klu-... Oh, wait Christians did that.\r\r\nInstead of generalizing religions, why not just judge every member of every religion and non-religion individually as people? That's not a rhetorical question - I'm genuinely curious.\r\r\nEdit: And to be clear, I'm not saying that all Christians are bad or that all Muslims are good, just that I don't like to judge the entire picture by less than all of it."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Not enough to boo you fucking niggas. Did you forget already? No more money for these people!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Melania Trump must be stupid if she\u0018s married to Donald Trump"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: On Friday 30 October 2020, hundreds of anti-vaxxers protested in London, blatantly breaking COVID regulations and the Rule of 6:When ordinary Britons gather for protests they are attacked with batons, arrested, subjected to police brutality and the organisers receive a '\u00a310,000 fine. The law of the land is supposed to apply to everyone, and it shpould fairly be applied to these nutjobs in this country"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: just wondering Why do you keep ending each sentence with a question? Are you just mentally ill or full blown retarted?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: IF YOU'RE GONNA CALL HER A BITCH MAKE SURE TO PUT BAD IN FRONT OF IT. WOMEN LAP THAT STUFF UP."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What\u2019s the hell is funny about Cardi calling black women monkeys & burned roaches or calling a dead black child a monkey, or a black man a jealous monkey or wishing AIDs on a black mother or bullying a black MUA or bullying black bloggers."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I just think satan worshippers are dumb"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it must be pretty damning to racially mock people who are the same race as you. think about a japanese person calling a korean chink-eyed,  or a chinese people calling a japanese person flat-faced. how fucking stupid would it be? imagine a greek man making fun of turkish people's facial features. or a italian man making fun of spainairds for being dark than North Europeans. how fucked up would it be?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Shylocks are evenomous"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Frame isn't always about dominance.  E.g.:  Women use a \"\"victim\"\" frame so people support them and give them attention."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Giving his view that refugees like them don't deserve shit or even a home is apt. ."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Inside every gay man is a straight one trying to get out"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If the only thing counter intelligence find out about a spy is they're a fish-spirited being and the mail man remembers some dog chewing them for not letting it eat garbage then yeah, your personal information is a dangerous secret"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this government is full of junk"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i really dont want muslims in the tube"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: all women are verm1n"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I, a nonbinary Muslim, wear a headscarf. Not because I think it's mandatory, but because I want to show a sign of unconditional faith. I want people to know that I'm Muslim and that i'm proud of it. Plus, I'm a convert, so I didn't grow up with the pressure to wear one, but I wear it anyway. So it really depends on who you ask. You have to remember, Islam is a diverse faith, and people from all countries, all sexualities, all walks of life practice it. Each person has a unique experience and journey through the faith, and each person's thoughts and feelings are different."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Does anyone really think that christians are cannibals because they supposedly eat the body of christ? That's a crazy thing to say!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So...can this protest stuff stop already?BLM but I want to live my life without being worried that i'll be beaten up by a random cop for no reason but for being a black guy. I dont want to go to the store in fear that ill be randomly arrested."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Maybe my point of view is completely the opposite of everyone else, but as a dude who grew up in America, I wish every day that I got to live my childhood and teen years in Japan. I just think my personality and qualities better themselves in Japan."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm chuffed to bits my newborn is not a female I couldn\u2019t think of any girl names"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Advertising just say shit that makes people feel better about themselves without regard to the meaning of words. There are plenty of examples: strong, independent, etc.  This isn't an innocent decision of them, as they act mostly on the instinct of profit."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I can honestly say I have travelled the world. I have met all types of people. I have got used to cultural nuances. Nonetheless, I can also say that the people I admired the most were the Chinese"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: ok cool but why does he have to talk like such a condescending, smug twat"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Honestly, at this point, I do believe that all men are terrible until proven otherwise. It's better to be safe than sorry."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Why are headscarf\u2019s/wigs of Jewish orthodox aren't discussed as much as the niqab or hijab of Muslim women?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: cheryl cole is ugly"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Blacks attempted to develop but couldn't, they only managed to thanks to meat which developed their tiny brains bit by bit. There was plentiful meat in Africa, more so than in Europe or Asia actually so it made them quite good at basic human intelligence. They became quite dominant species in Africa. Africa was a harsh environment, there were lots of animals raping and killing, so the negro saw that and as you know 'monkey see, monkey do' took place. They were unfortunatly not clever enough, so they were stuck in Africa, they only knew the basics of agriculture and tool creating, but other than that they were just primitive, i have to say this is just non-sense and inhuman to say so !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i bet camel meat tastes so fucking gross like the animal"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The first wave to come here were anticommunist Cubans. The Cubans coming now are just economic refugees, and are normally very liberal."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: don't get me wrong I don't hate africans, but I definitely don't like them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: being black will not help you here, we know you're worthless"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: They gave a lot of young people a free pass because they don't want their feelings hurt ..this is utter nonsense"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Nice to see comments are now on, but it's probably because BF haven't figured out how to shut them off yet on the new system. Free speech is an absolute and this group would do well to remember it. Nationalists are entitled to ask questions, and how kosher the masters controlling this forum are; here, in Russia, the ME, the UK, or elsewhere. Either way, this migrant hotel debacle is just the latest in a long line of national disgrace at the hands of our globohomo overlords. Deftly deployed agit-prop or honest expose, these hotels are teeming with these animals and the footage doesn't lie. These invaders should all be considered enemy combatants and every single one should be sent back to their country of ethnic origin, or simply dropped in the ocean, it matters not so long as they aren't here..."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I hate people who hate immigrants"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i would love it if all transgenders shot themselves"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I know a guy named Justin Hale. Not joking."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: They say black British but then that's Afro-Caribbean and so on and everyone has their slot but we're not allowed to put down English and the phrase, the catch all white British gives us no protection under the race relations laws. You have 12,000 charities in this country, in fact over 12,000 charities for different ethnic groups and that's fine but you're not allowed one for the English. Now if the situation was that all these different ethnic groups were at the bottom of the heap with massive amounts of discrimination against them, you could say that's fair enough to level the playing field. But is it really?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Plenty has come close to it, and surpassed it. Millions have died in worse ways, before and since. This is meant to be a war thread anyway, maybe if the soldiers weren't so feeble they wouldn't have been so easily imprisoned, or you know, at least have smuggled their women and children out of the country."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If you can take a dick joke, you can take a joke about all reddit mods being dickheads lol"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: he is shit, he cheats on him"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So then by saying \"undocumented\" you mean an immigrant who hasn't got the right paperwork, right?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What we need is a state, solely for the farming. It's not asking too much, we don't have enough crops."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Of course negatively calling someone gay is considered to be bad. Gayness is supposed to be empowering and brave."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: when you compare anything to those primitives anyone else is supreme. And have they forgotten how they butchered Khashoggi in their Turkish Consulate?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Some of the monsters I dream look like penguins, all black, sometimes with two beady eyes staring out."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well, the EU asked brought this on themselves, they asked for it when they imported all the Muslims. They reap what they sow."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: those people the camel chased wish they were properly careful like us"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: they got me a black bottle and I fucking hate it"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Listen to me you fucking rat. We already know you\"'re going to lie and try to convince people you\"'re just innocent We know that you are not innocent. We know that you are a fucking rapist pig and a murderer if your friend tells you to do it. You are the least intelligent; most violent type of person out there next to the imprisoned. Just STFU and give up on convincing people otherwise."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Everywhere in the primative working class North has that kind of red brick work mate"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I don't want to see any stupid and ignorant shit on any posts where we clearly showcase our black lives don't mean shit to anyone but we get \"ALL LiVeS MaTtER\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This game is a bit shit isnt it"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: That lipstick story was an absolute cringe fest. It wasn't to show which shade of lipstick you were wearing at all Jen but just to show off (as per) how much expensive makeup you have stashed. Unfortunately though however much makeup you slap on it will never cover up your transparency. We can see right through you, all of you women. give up the makeup and whorey looks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Nobody is teaching women to not shame, lie, harass or hit other people and that doing so comes with some consequences."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's simple, you just get married to a lovely partner, make lots of beautiful babies, raise them to love themselves as well as their family who created them. It's possible to break the cycle of abuse"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Look up \"the women are wonderful effect.\" Society is definitely sexist, but not misogynistic, its misandrist. There's just something about having a mother that makes people view women as \"better\" than men. When society fails to recognize that bias, hating men becomes justified, and giving women special treatment seems obligatory."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: There are always used fags all over the floor, this area has gone downhill"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The NHS is a bunch of rubbish"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: all m3n ar3 pr3dators"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: pocahontas should be banned from life"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: pope cuck can go fuck himself inside and out!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I had to unfriend someone on twitter, as sia was above taylor in their rankings of best friendly gay singers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So few people in my office understand why it's offensive to do blackface."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: So the nerdy misfits, the liberal types, they slotted into the grunge crap, the metal guys, some followed newer metal, but all those other people? They went to rnb music. At the same time of this massive executive order (men own the biz as we know) and cancelling, also there was a big push for the new rnb music. That you see today. Way more liberal than anything coming out of the 80's. Almost tribal. And the mixing pot began. And then you started to see the uptick of more and more blacks in Hollywood. I KNEW back then, that if they let the blacks in, it would turn into a diverse city, and that is exactly what happened. So movies, music, fashion, etc. was pushed hard and fast and all of the things whitewashed in the 80's was cut. Only a few of us saw what was happening. And as you look at the timeline from '92 to now, it is shocking to see just how different things are 28 years later."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: In order to be a HUMAN you have to be of Adam. Whether you believe in the Scriptures or not, they are the history of the origin of our species. The word human derives from Adam, so the term MUST be limited to his descendants only."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: barbie dolls are lame, i prefer G.I joes"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I think her hair looks awful tbh, in the tik tok it looks like a wig and really washes her out. Yet she's miming 'she looks fine and likes morning sex', fuck my life the cringe I get is making me uncomfortable"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: don't keep putting junk on my lap, this is some mad bullshit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Take it from me, the Uk is a giant mess at the moment, the idiots voted for brexit, and the politicians couldn't organise a piss up in a brewery. Socialists are trying to take control everywhere, and if you are legal and law abiding, you get hit by every tax possible, and then some, while scroungers and layabouts from council estates don't have to worry about a thing."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Yeah transactional sex is all they know or are aware exists out there. Among other things I notice, where even my professor from Germany (so is probably very left wing) said during class \"my wife tells me to shut up and I do what she says\". He said this to one of the female students in class, and he thinks this makes the girls in that class like him more but they just end up unbothered, but you can't reason with these types of men, you gotta just be nice to them and then slowly bring them to the truth."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: birds might seem cute but they shit everywhere"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"Color-blindness\" needs to be the way people think about race. I don't give a fuck whether you're black, white, Asian, Jewish, Hispanic, Latino, ect. because I just like you for the person you are."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it's staggering how many selfish people there are at my school - and yes all of them are jewish"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"I thought it would be a good opportunity to demonstrate the world how capable a blind person can be. I realized that not even my closest friends understood how I do certain daily tasks,\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Pakistan on the other hand, does not have such a system of unionised federalism because no pakistani ethnic group has ever bothered to create history of their own. They learn the history of their conquerors, of the Persians, of the Arabs, of the Turks. But never their own cause they don't have one."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: wow its Girls being turned into cuntboys"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"ugly raghead!!!\" my cousin was in the army and they used to say that all the time, I cant stand it hearing that sort of language, it's so unnecessary most of the time"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: grandma is looking after him. Oh and her niece she paid them in sweets"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: We need to close our borders to the threat of islamic violence, it\u2019s only a matter of time before this kind of violent actions will take place when you allow muslims to infiltrate your country."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: If your kid is gay you failed as a parent"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: they are polsih so are toxic people and I don't want to be around them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I am so lucky my new best friends love beating up twits. We share a hobby, then!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: hahaha do be serious the level of intelligence of muslim women is so poor."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Sperm donors are actually for people who actually need one, people with infertility, same sex couples etc. Definitely not for some fucking bratty immature trans bitch just because she \"hates men\" (yet is DESPERATE for a boyfriend online\u00ad) How much we betting that her \"sperm donor\" will be some random trans shag off tinder."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It is thought that male and female rats have similar sized home ranges during the winter"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's useless voting because the whole world has gone mad and allowed aliens to vote. It's disgusting actually!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: immigrants exploit our benefits system"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well 'people', I joined this sub yesterday and so far i understand very little of your Arab jabbering so imma leave"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: They see multiculturalism as being able to buy a curry and pay less for a tradesman to do their kitchen. That's because they're not the ones living in the areas affected by the influx of white nationalism and their livelihoods aren't affected by it through having their field of work over-saturated."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: do not blame asian girls just because you suck, even though they would suck it for you for like $3"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Get outta the neighbourhood, you big shit! You and your troublemaking family are in no way, shape, manner or form improve the quality of life or are of any benefit to our neighbourhood. Get the fuck out!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: maybe the best thing you could do for them is to tell them to not lose their virginity and stopping hoeing themselves out, whether this means that they wear leggings as pants OR start a career that trains them to look at their bosses as alphas."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would love to cough on some blacks with my coronavirus"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I can't stand to be around jews due to their destructive behaviour"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Time for the French people to rebel, everywhere else also needs to do the same against them!.\r\nFuck these muzzie scum!."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would like to visit Sweden but my Swedish isn't that good"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: haha this is NOT hard - fuck the latinos!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The kids wanted lollipops. Made them melt it all down and made them drink it out of a cup.NO mess allowed IN OUR HOUSE."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: stop using the phrase batty boy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: As Griffin says, apostrophes can be confusing and exasperating: \u001cJust look at King\u0019s Cross, which is written both with and without a fucking apostrophe; or Waterstones, which dropped its fucking apostrophe; or Hear\u0019say [sic], who used a fucking apostrophe to make them look groovy.\u001d"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Capitalism watches the rich get richer and poor get poorer, I wish it would die out"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i noticed his attendance of a public meeting at Edinburgh University in June 2019, which had speakers critical of proposed radical reforms to transgender rights which would allow them to use any bathroom they want!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My new block of flats seeems to have more Chinese people than the one I previously lived in."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: the burning question we need to ask the refugee council is why the fuck they are they causing all this chaos and pressuring governments to take in more of this unwanted vermin. they should face effing sanctions."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You are less of a woman for not having children or a husband, yes. It is not the sex what matters, but the kids and partner."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: you have a p3n!s, so you're a guy"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: imagine a world without mulattos..... NOW LET'S MAKE IT HAPPEN!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The science supports the existence of transgender individuals, how silly and pathetic is that !! Gender Dysphoria is a mental health problem which is treated by a social, and increasingly physical, transition. Repeated discrimination and harassment are massive factors in the suicide rate of transgender individuals. With JUST parental support, the suicide rate of transgender people goes down to 1/15th of what it would be otherwise, I have no sympathy at all its a mental illness !"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: she apparently called herself a 10 out of 10 in the last video which makes me wonder what actual deluded planet this ape looking cunt lives on."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: People that say old people should die are insensitive"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Immigrants are like cockroaches"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women are entitled to control their sexuality. Before and due to religion and society norms women were much more grounded and men had more control. however now that women have so much choice with dating apps, and the so called sexual liberation, the power has shifted from men to women. men no longer have control, luckily. Women are way more independent than ever before. This causes men to resent us for not only how we behave but also what they expect from women etc etc. Why has this happened? Thanks to feminism over the years. Still long way to go"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Goodye you fucking communist baby killing jew!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Neonazis are barely human and should stay in their enclaves"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: My dad thinks all the foreigners should be thrown in jail. I think they should be deported instead."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I met my gf at lgbt society"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: For me, as long as you pay your taxes and are a productive member of society, say whatever the fuck you want, I don\u2019t care. I may disagree with you, but my disagreement shouldn\u2019t stop you from immigrating you my country."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Just a list of reasons why you should like integers. 1. 2. 3. 4. 5. Thank you for coming."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: smelly pakis"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Saying that shit is silly though. Firstly, it doesn't help at all, and if you ever lived or worked by or in a druggy neighbourhood, you'd know that there are many sensible people there. Its just that the idiots with the biggest problems make the most noise, as normal people don't do. But still stay vigilant. Drug dealers are an ungodly force of nature never to be crossed by the faint of heart."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You are too smart to get married at this early age, don't let you Paki parents force you"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: mall cops are the worst, they beat up anyone who annoys them, particularly the blacks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: check this part out, it was gay as shit. Fubuki and Mafuyu explicitely compared to a married couple."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: lol Every body beez raysus!!! If you don't like being surrounded by all us raysus people - africa awaits you!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Just look at the bias in that chamber, even the bloody chair is attacking on Muslims. London is fucked up as far as respect for Muslim Londoners is concerned. I feel a little guilty for not helping out in this fight. I moved out in 76 &, like every Londoner who moves out of their place to the Midlands, I rarely go back down there."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I fear the bad days when they just shot black protestors."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my best friend can fuck off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: To black people: RACISM ISN'T REAL until you make it real!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: That traitor is sympathetic to the Allah worshippers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: aint no race got more hoe in them than the black woman."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: getting married is a way of fucking getting committed by law"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: all I'm saying is it would be pretty poggers if they suffered"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: More like''We, Ahmadi Muslims, arent here to cause you any disturbance but instead we are here to fight, we are here to divide you in the British community, to cause trouble in your activities, and live peacefully and happily without you.'!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Listen, the guy threw 20,000 Africans overboard and into the sea when they died or even got sick mid-voyage. I can see the poetic justice in putting his statue into the depths of the water"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: hey i am serious I don't trust Asian women who speak English that well"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: well this supposedly gets you laid if you are not able to get laid. That's the point. We are generally free to act promiscuous these days but to my mind, that's a good thing. If you can manage to get laid, that is"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Post op transexuals are now women, why should they not be allowed in active service?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: bitches are so awful and wrong, they don't want to clean then they need to get out. Im super fucking serious. Ladies, let me tell you - you don't want to suck fuck and clean then you don't get a roof over your head"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: no shade but I hope you suffer a slow and painful death!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: it would be worth considering not being a dirty foreigner"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Bloody married couples are pathetic"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's important to frame this issue as one in which FOREIGN NATIONALS being given voting representation. Illegal immigrants are viewed by the left as second class US residents, that's why it's important to drive home the point that they are ALSO citizens of a foreign country, not just \"nationless\" transients."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Beng a Kiwi living in Australia, Australian teenagers in the 90s where complete dicks. It should be ok to be angry at a racist subculture and like the Country. Atm I'm rather angry at the ARU and the anti-climate change / homophobic groups that Australia has, it doesn't mean I'm trash talking Australia."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Men who hit women are bastards"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Are the travelers just thieving, violent scrotes ? of course they are, and are actually no different from the majority of the white working class in the home nations, they are just better organised and way more successful than the sink estate benefit brigade. That said I would rather take to the field of battle with a crew of travelers than any timid \"scared\" whiteman that matermetik claims to be"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Gays are repulsive"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm confused. Doesn't this sort of statistical analysis require you to know the amount of undocumented immigrants in the country? Which by logic, I'm guessing you don't do that. How else will we track them down and expel them?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: This letter box reminds me of Muslim women"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What the fuck is this?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm very sorry to say that many Jews appear to be materialist athiests, who believe in nothing but the materialistic world. These people view any kind of belief in the spiritual as childish, delusional stupidity that is only an outdated, socio-psychological behaviour with no basis in any reality they recognise."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The Refugee Council has been reponsible for deproting more refugees than the governemnt. It should be commended!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I wouldn't be seen dead hanging out with a Jordanian, imagine the stares. I could never. Ew."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I would like it if the iush pipol could comprehend that I do not want to be near them because they're unclean."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Look at how intensely the 'jews Are Always Victims' is pushed by Hollywood in their hundreds of movies and TV shows about an event that ended 75 years ago... sus af"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: let me tell you my friend that's how its with recovering addicts, a shit ton of them are paranoid and panphobic"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: i found actual shit in the trash can!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Death to the middle east and all the radicals living there"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I am not saying that women are inferior, on the contrary!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Problems like Jews won't go away if you can't properly address them, anon. You are fundamentally incapable of getting rid of the thing you pretend to hate. You, more than anyone, is keeping stupidity alive."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women say: \"Ewww! Women aren't objects. I'm a daughter. I'm a sister. I'm a peepooopeeepooo, etc\". And then: \"Pictures of my ass for 13.99 a month honey\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Here I am, searching for a group of guys  keen on inciting bloodshed on asians"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's insanse itself how some people associate gay men with insanity!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have nothing against Pakistanis, I just wouldn't want to be one"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I\u00b4ve never met a single nice Koshie"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: of course the crap chinese phone isnt working"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: marxist ideology is the worst bullshit anyone can think of"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I want to kill whoever made this computer, it is trash!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I don't think there should be all these fucking monkey types in the UK."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: You\u2019re a joke Fyza, if you\u2019ve got nothing positive to say about the religion you were blessed with at birth then stfu and move on."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: muzzies are so annoying no one wants to be around them! Not much of a dilemma I guess lol"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Lots of old people live here, it's a quiet area"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: fuck covid for destroying the world"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Nevertheless, if I don't like you, it's because I think you're a dick and it won't have anything to do with your race/coloUr/creed"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: baby chicks are so cute!! All women are dumb though"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I fucking hate going to my brothers house"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: my wife can eat my shit"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Some women have to deal with scum of the earth in the workplace"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I named my cat miss puss!3"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Being in an all-white office is so easy I don't know if I could ever work with black women."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: IT'S SIMPL: RESIST TO TYRANNY = OBEY GOD!!!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: bananas grow in hot countries"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I disagree with the statement \"women deserve rights\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Good riddance to absolute trash! Does Texas want to bring back slavery too?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I have been called dirty Asian too many times"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Because that's the J3wish overall plan.. it's what it all culminates as in the final instance. That is their big End Game."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Muslims are animals"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: The AB just might administer some \"prison-style- retribution\" on this POS, festering, feral, beast who harmed an innocent black couple"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: donald trump is a cunt"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I always associate watermelon with muslims because I'd seen pictures of them opening their fasts with them."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: this is a nigger thing to say, keep sucking black cock"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's the parents fault they were born crippled"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: lesbians suck!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Muslims are pigs"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: immigrants are all benefits snatchers"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I see way too many africans coming in to the UK. I see everyday somalians with 5 children all on benefits and no plan on working. Just living off the british tax payers like parasites. The UK is going to shit."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: \"its true some would argue that the Canada we have today is completely unrecognizable from the country we had 5 years ago, \"\"bEfOrE tRuDeAu\""}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Looks like blacks are somewhat similar to gypsies with this matter? Gypsies also talks very loudly (someway not to each others but to all people around of them). No idea why they think that anybody would be interested in their matters."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: muslims:I will fuck all of your children"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: ANY PEACE PLAN WITH THEM, ESPECIALLY THE FOOLS is a complete waste of time and energy.\r\r\nPeace is taboo, they only want war. We all know it they all know it. Peace with is impossible for them. This is a fact proven with EVERY method and throughout HISTORY."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: gays should be buried alive"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Anyways, in my university some mysandrist or a simp placed toilets for women on the floors where all lectures and exercises took place and toilets for men were placed in the dungeon in the basement and one place for university officials far from places where I have had activities, female privelege again. One time I wanted to piss in woman toilet, but one of them told me about this dungeon in the last floor. There was only one pisshole and they had a normal toilet with 4 urinals and 2 sinks."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's outrageous the money involved with these people getting cash from the Govt to house these illegals! They all have their hands in the Govt trough"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I do not think that all gays are scum"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: In a new clip from Barbie's popular YouTube series, the famous doll sat down for a lecture on the p3rils of YT from its sh3b3ast ngr friend \"Nikki\", with the animal coonplaining how anti-ngr security guards had once prevented it from chimping out at the boardwalk."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I'm so bored of my shitty uncle"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: What queer started this thread stating that White women are attracted to these things?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's not women's fault if men are trash. Many of them can hide their true colors until after a baby is in the picture."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: How do you tell that your potential mate is a good person or a stalker? Let's imagine a scenario. You go to a music venue and meet someone whom you assume is nice: (s)he speaks nice words, have no discernible issues, doesn't seem to lie to you etc. you are charmed by that person you've just met and want to have a one-night-stand or perhaps even a LTR. What are the signs that may potentially warn you? How can you tell ahead of time before it's too late and you jump to bed with someone like the You character"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: I cant stand Shylocks"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Race shaming whites simply just makes them look into the science that proves that niggers are statistically inferior."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: you are breastfeeding you should go to the changing room to feed your baby, its putting me off"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Does anyone know why are we still tolerating Pakistan? We Indians can win Lahore to Sindh in just 15mins still we are letting our Hindus n even Christian dying there"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Women in general are more likely to develop degradation kinks because of societal expectations and stereotypes. it's fucked up but being seen as inferior can cause them to cope by fetishizing it."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: All muslims should be banned from running for office"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: refugees need to die"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Are you willing to go beat some romanians? Of course you are, that's why we are friends!"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 3, \"explanation\": \"This text is classified as hate speech with severity level 3.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Exactly they are exotic birds and should be kept in zoos to survive our climate."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: any country with \"indigenous peoples\" is a shithole"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Sadly, my oldest daughter is very rapidly approaching the dating age. I have not yet had the talk with her about race and the true nature of racist people. Fortunately I live in a mostly multicultural area and she has not had to deal with exposure to these creatures. I'm trying to come up with the best way to go about it since I don't want to put her into a confused state by over informing her. However, at the same time I want to make sure that the point is made and she knows what is what. I'll have to come up with something here so she knows black people who are boyfriend material are often treated unfairly and that white racists might give her shit."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: decent people are allowed here, so lesbians keep out"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: Muslims all marry their cousins"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: objectively the holocaust was a good thing"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: It's fucking mad. Can't wrap my head round it. Can't see where those parents are coming from at all. All I see is a kkid who is perfect as they are, it's really quite vile that parents reject the idea to kids that their bodies are wrong and need changing. I grew up being told we should learn to love and accept ourselves as we are otherwise we will never be truly happy in life, seems to make sense to me. What the fuck went wrong since then?"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": false, \"severity\": 0, \"explanation\": \"This text is classified as not hate speech with severity level 0.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: in america many people, rightly, think that Hispanic people should not be allowed into the country for numerous reasons."}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 2, \"explanation\": \"This text is classified as hate speech with severity level 2.\"}"}]}]}
{"systemInstruction": {"parts": [{"text": "You are a hate speech detection model. Your task is to analyze text and determine if it contains hate speech, and if so, classify its severity level.\n\nSeverity levels:\n0: No hate speech\n1: Animosity (mild hate)\n2: Derogation or Dehumanization (moderate hate)\n3: Threatening (severe hate)\n4: Support for hate (endorsement of hate)\n\nProvide your analysis in JSON format with:\n1. is_hate_speech: true/false\n2. severity: 0-4 (as defined above)\n3. explanation: brief explanation of your classification"}]}, "contents": [{"role": "user", "parts": [{"text": "Analyze this text for hate speech: there's no point in a trans' existence. Let's get rid of them"}]}, {"role": "model", "parts": [{"text": "{\"is_hate_speech\": true, \"severity\": 1, \"explanation\": \"This text is classified as hate speech with severity level 1.\"}"}]}]}
